---
title: "halo_facestudy_spoken_analysis"
author: "Helio"
date: '2022-08-30'
output: html_document
---



dependencies: preprocss_halofaces.Rmd
df_OF_output_AUsW_unblind_posed_binned

related script:analysys_halofacestudy.Rmd
related data: df_OF_output_AUsW_unblind_posed



for the actual analyses we want
1- learn spatiotemporal structure suing NMF
2 - does drug vs no drug differ in NMF metrics?
3- can we separate groups based on NMF components using BADIA

spatiotemporal dynamics
- movement substates (initiation, sustainment, etc)
- if we use kmean clustering, do we have differences into how many substaes are there
- or if we use a fixed number of substates, are there significant temporal differences (e.g. duration, recurrence)

preferences
```{r}
library(tidyverse)
library(data.table)

library(NMF)

```

for the NMF we will start with k = 3 given our findings in the posed (we have a good prior for 3). 
But then we will also do 1 to 4 to to compare.

fit nmf just spoken
```{r}

unique(df_OF_output_AUsW_unblind_spoken1_2_binned$posed.spoken)

df_OF_output_AUsW_unblind_spoken1_2$bin

# use only the "spoken" condition
df_OF_output_AUsW_unblind_spoken1_binned<- subset(df_OF_output_AUsW_unblind_spoken1_2_binned,
                                           posed.spoken == "spoken")



# fit
colnames(df_OF_output_AUsW_unblind_spoken1_binned)
res_k3_spoken1 <- NMF::nmf(df_OF_output_AUsW_unblind_spoken1_binned[,17:33], r = 3, 
                  nrun = 200, #number of runs to try and update for
                  seed=123456, #specific seed for reproducibility
                 .options = list( 'v')) #verbose



# plot(res_k3_spoken1) - this only work for multyiple fits with multiple ks
# summary(res_k3_spoken1) #dont run

# basis components 
NMF::basismap(res_k3_spoken1) # weights/ amplitudes
# memory exhaust - takes a lot of time

# mixture coefficients 
coefmap(res_k3_spoken1) #hidden variables

# access more info
# res_k3_em

```


some custom visualisations

custom visalisation of H (mixing components)
```{r}
# chool_talk$AU_NM 
paper_plots$spoken_NMF_hm <-
as.data.frame(res_k3_spoken1@fit@H) %>%
  mutate(component = c(1,3,2)) %>%
  gather(AU, coef, -component)%>%
  group_by(component)%>%
  mutate(max_comp = max(coef),
         coef = coef/max_comp,
         # AU = substring(AU,8,40),
         AU_code = substring(AU,4,5)
         )%>%
  arrange(AU_code)%>%
  ggplot(aes(component,AU, fill = coef))+
  geom_tile()+
  theme_classic()+
  # scale_fill_viridis_()
   scale_fill_viridis_c(option = "magma", breaks=c(0,.5,1),
                       limits =c(0,1))+#)+
  xlab("K")+
  p$graphstyle_int+
guides(fill=guide_colorbar(ticks.colour = NA))+
    xlab("Component (K)")+
  ggtitle("SPOKEN EXPRESSIONS")
  

paper_plots$spoken_NMF_hm


```


store components in the dataset
```{r}
# store nmftable in DF
df_OF_output_AUsW_unblind_spoken1$NMFtable_k3<- as.data.frame(res_k3_spoken1@fit@W)$V1

# store components
df_OF_output_AUsW_unblind_spoken1_binned$k3_comp1 = as.data.frame(res_k3_spoken1@fit@W)$V1
df_OF_output_AUsW_unblind_spoken1_binned$k3_comp2 = as.data.frame(res_k3_spoken1@fit@W)$V2
df_OF_output_AUsW_unblind_spoken1_binned$k3_comp3 = as.data.frame(res_k3_spoken1@fit@W)$V3



# visualisation based on time


# chool_talk$ts_smooth<- 

colnames(df_OF_output_AUsW_unblind_spoken1_binned)
# colnames(  df_OF_output_AUsW_unblind_spoken1[,c(1,6:7,9:10,33:35)])
  
  
  df_OF_output_AUsW_unblind_spoken1_binned[,c(1,2:3,9:10,34:36)]%>%
  gather(component, coef,-bin_frame, -subject, -expression, -drug.placebo,-filename)%>%
  
      group_by(filename,component,subject,expression)%>%
  mutate(coef_max = max(coef),
         coef = coef/coef_max) %>%
  
  group_by(expression, component, bin_frame,subject)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  # ggplot(aes(Dataset, coef , color = Dataset, fill = Dataset))+
  ggplot(aes(bin_frame, coef, color = component))+
  geom_smooth()+
  # geom_smooth(aes(group = subject), se = F)+
  # stat_summary(aes(group = subject, color = component), geom = "smooth")+
  facet_grid(~expression )+
  theme_classic()+
   xlab("time bin")+
  p$graphstyle_int+
   scale_color_viridis_d(option = "magma")
  
  
  # ts by expression
   df_OF_output_AUsW_unblind_spoken1_binned[,c(1,2:3,9:10,34:36)]%>%
  gather(component, coef,-bin_frame, -subject, -expression, -drug.placebo,-filename)%>%
  
      group_by(filename,component,subject,expression)%>%
  mutate(coef_max = max(coef),
         coef = coef/coef_max) %>%
  
  group_by(expression, component, bin_frame,subject)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  # ggplot(aes(Dataset, coef , color = Dataset, fill = Dataset))+
  ggplot(aes(bin_frame, coef, color = expression))+
  geom_smooth()+
  # geom_smooth(aes(group = subject), se = F)+
  # stat_summary(aes(group = subject, color = component), geom = "smooth")+
  facet_grid(~component  )+
  theme_classic()+
   xlab("time bin")+
  p$graphstyle_int+
   scale_color_viridis_d(option = "magma")
  
  
  # heatmap
  
  
  # chool_talk$ts_hm<-
df_OF_output_AUsW_unblind_spoken1_binned[,c(1,2:3,9:10,34:36)]%>%
  gather(component, coef,-bin_frame, -subject, -expression, -drug.placebo,-filename)%>%
  group_by(filename,component)%>%
  mutate(coef_max = max(coef),
         coef = coef/coef_max)%>%
  # mutate_at(c("coef"), scale)%>%
  group_by(component, expression, bin_frame)%>%

  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  # ggplot(aes(Dataset, coef , color = Dataset, fill = Dataset))+
  ggplot(aes(bin_frame, component, fill= coef))+
  geom_tile()+
  xlab("time bin")+
  scale_fill_viridis_c(option = "magma")+
  # geom_smooth(se = F)+
  facet_grid(~expression)+
  theme_classic()+
  p$graphstyle_int+
  guides(fill=guide_colorbar(ticks.colour = NA))+
  theme(panel.spacing = unit(1, "cm"))
  




library(patchwork)
# 
# chool_talk$ts_nmf_heat_NMF <- (chool_talk$ts_smooth/
#   chool_talk$ts_hm)+
#   plot_layout(heights = c(1,2))
# 
# chool_talk$ts_nmf_heat_NMF
# 
# ggsave("ts_nmf_heat_NMF.tiff", chool_talk$ts_nmf_heat_NMF, device = "tiff",
#        width = 10, height = 7, dpi = 800)

```

combine sooken and posed

```{r}
spoken_NMF<- df_OF_output_AUsW_unblind_spoken1_binned[,c(1,2:3,9:10,34:36)]

posed_NMF<- 
df_OF_output_AUsW_unblind_posed_binned[,c(1,2:3,9:10,34:36)]

df_OF_output_AUsW_unblind_spoken1_binned$k3_comp3

posed_NMF$k3_comp1<- posed_NMF$comp1
posed_NMF$k3_comp2<- posed_NMF$comp3
posed_NMF$k3_comp3<- posed_NMF$comp2

posed_NMF$comp1<- NULL
posed_NMF$comp2<- NULL

posed_NMF$comp3<- NULL

posed_NMF$posed_spoken<- "posed"
spoken_NMF$posed_spoken<- "spoken"


# bind_rows(posed_NMF, spoken_NMF)%>%
paper_plots$spoken_NMF <-
  spoken_NMF%>%
  gather(component, coef,-bin_frame, -subject, -expression, -drug.placebo,-filename,-posed_spoken)%>%
  # subset(expression!= "neutral")%>%
    mutate(component = substring(component,4,8))%>%
  
      group_by(filename,component,subject,expression,posed_spoken)%>%
  mutate(coef_max = max(coef),
         coef = coef/coef_max) %>%
  
  group_by(expression, component, bin_frame,subject,posed_spoken)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  # ggplot(aes(Dataset, coef , color = Dataset, fill = Dataset))+
  ggplot(aes(bin_frame, coef, color = component))+
  geom_smooth()+
  # geom_smooth(aes(group = subject), se = F)+
  # stat_summary(aes(group = subject, color = component), geom = "smooth")+
  facet_grid(~expression )+
  theme_classic()+
   xlab("time bin")+
  p$graphstyle_int+
   scale_color_viridis_d(option = "magma")+
    scale_x_continuous(breaks=c(0,50,100), limits = c(0, 100))+
    scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))+
  theme(panel.spacing.x = unit(1.5, "lines"))+
  theme(legend.position = "top")
  
  paper_plots$spoken_NMF
  
  
  
  # ts heatmap
  # df_OF_output_AUsW_unblind_spoken1_binned[,c(1,2:3,9:10,34:36)]%>%
 paper_plots$spoken_NMF_ts_hm <- 
  spoken_NMF%>%
  gather(component, coef,-bin_frame, -subject, -expression, -drug.placebo,-filename,-posed_spoken)%>%
  # subset(expression!= "neutral")%>%
    mutate(component = substring(component,4,8))%>%
    mutate(expression = factor(expression, levels = c('angry', 'happy', 'sad', 'neutral')))%>%
  
      group_by(filename,component,subject,expression,posed_spoken)%>%
  mutate(coef_max = max(coef),
         coef = coef/coef_max) %>%
  # 
  # gather(component, coef,-bin_frame, -subject, -expression, -drug.placebo,-filename)%>%
  # group_by(filename,component)%>%
  # mutate(coef_max = max(coef),
  #        coef = coef/coef_max)%>%

  group_by(component, expression, bin_frame)%>%

  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  # ggplot(aes(Dataset, coef , color = Dataset, fill = Dataset))+
  ggplot(aes(bin_frame, component, fill= coef))+
  geom_tile()+
  xlab("time bin")+
      scale_fill_viridis_c(option = "magma", breaks=c(0,.5,1),
                       limits =c(0,1))+#)+
  # scale_fill_viridis_c(option = "magma")+
  # geom_smooth(se = F)+
  facet_grid(~expression)+
  theme_classic()+
  p$graphstyle_int+
  guides(fill=guide_colorbar(ticks.colour = NA))+
  # theme(panel.spacing = unit(1, "cm"))+
    scale_x_continuous(breaks=c(0,50,100), limits = c(0, 100))+
  theme(panel.spacing.x = unit(1.5, "lines"))

  paper_plots$spoken_NMF_ts_hm
  
  
  # panespoken_NMF_ts_hm paper_plots$spoken_NMF_ts_hm
  paper_plots$NMF_panel_spoken <-
(paper_plots$spoken_NMF_hm |
  (paper_plots$spoken_NMF/paper_plots$spoken_NMF_ts_hm))+
  plot_layout(ncol = 2, widths = c(.7,2))+
    plot_annotation(title = "SPOKEN EXPRESSIONS")

    paper_plots$NMF_panel_spoken
    
    
ggsave("fig2_NMF_panel_spokjen.tiff", paper_plots$NMF_panel_spoken, device = "tiff",
       width = 14, height = 7, dpi = 800)


paper_plots$panel_fig2_posed_spoken_panel<- 
  ((paper_plots$NMF_panel_posed+ggtitle("POSED EXPRESSIONS")) /(paper_plots$NMF_panel_spoken+ggtitle("SPOKEN EXPRESSIONS")))+
  plot_annotation(tag_levels = 'A')

paper_plots$NMF_panel_posed +
  ggtitle("posed")
  
ggsave("panel_fig2_posed_spoken_panel.tiff", paper_plots$panel_fig2_posed_spoken_pane, device = "tiff",
       width = 20, height = 14, dpi = 800)

```



```{r}
posed_spoken_bindrows<- bind_rows(posed_NMF, spoken_NMF)%>%
  group_by(filename,posed_spoken, expression, drug.placebo,subject)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)

posed_spoken_bindrows_ts<- bind_rows(posed_NMF, spoken_NMF)%>%
  group_by(filename, bin_frame, posed_spoken, expression, drug.placebo,subject)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)


View(posed_spoken_bindrows_ts)

colnames(posed_spoken_bindrows)

write_csv(posed_spoken_bindrows, "posed_spoken_bindrows.csv")
write_csv(posed_spoken_bindrows, "posed_spoken_bindrows_ts.csv")

caret::createDataPartition(c(2:9),
                            2, p = .7, group = "filename")
posed_spoken_bindrows_ts

library(caTools)

?sample.split


posed_spoken_bindrows_ts$trainLogical<-sample.split(posed_spoken_bindrows_ts$k3_comp1, group = posed_spoken_bindrows_ts$filename, SplitRatio = 0.7)



posed_spoken_bindrows_ts$trainLogical_num<-as.numeric(posed_spoken_bindrows_ts$trainLogical)
table(posed_spoken_bindrows_ts$trainLogical)/length(posed_spoken_bindrows_ts$trainLogical)
table(posed_spoken_bindrows_ts$trainLogical_num)/length(posed_spoken_bindrows_ts$trainLogical_num)


write_csv(posed_spoken_bindrows_ts, "posed_spoken_bindrows_ts.csv")




```


install.packages(sktime)


MULTIVARIATE TIMESERIES CLUSTERING
```{r}
# Load the caret package
library(caret)

# Split your data into training and testing sets
train_ind <- createDataPartition(y, p = 0.7, list = FALSE)
train <- posed_spoken_bindrows_ts%>%subset(trainLogical_num == 1 & posed_spoken == "posed")
test <- posed_spoken_bindrows_ts%>%subset(trainLogical_num !=1 & posed_spoken == "posed")

# Specify the model and tuning parameters
train
colnames(train)

?caret::train()

caret::getModelInfo()
model <- train(
  expression ~ .,
  data = as.matrix(train[,c(4,7:9)]),
  method = "rf"
  # tuneGrid = expand.grid(cost = 10^seq(-3, 3)
                         # )
)


# Classification with decision tree
library(party)
ctre
tree <- ctree(pattern100~., newdata)

# Classification performance
tab <- table(Predicted = predict(tree, newdata), Actual = newdata$pattern100)
sum(diag(tab))/sum(tab)

install.packages(jasp)


tree <- ctree(train$expression~., train[,7:9])

# Classification performance
tab <- table(Predicted = predict(tree, newdata), Actual = newdata$pattern100)
sum(diag(tab))/sum(tab)


# timeseries classification test
# Install from GitHub using devtools package
install.packages("devtools")
devtools::install_github("fjbaldan/CMFMTS")

library(CMFMTS)
?CMFMTS::cmfmts
# Data to process (data.frame). Each row contains a time series.


train
# DTW test
?tidyr::gather()

train_gather<- bind_rows(train, test)
train_gather<- gather(train_gather[1:9], key = "nm_comp", value = "nmf_comp_value", - c(1:6))
train_gather

train_gather$timersies_unique <- paste0(train_gather$filename,paste0(train_gather$nm_comp))
unique(train_gather$timersies_unique)


# train_gather_comp1 <- train_gather%>%subset(timersies_unique == "./cut_posed_angry_day1_p10.csvk3_comp1")
# i need to dcast time ids to rows, because this fucntion needs each row to be a timeseries

ts_order<- c(paste0("t_",(1:100)))

(ts_order)
warnings()


colnames(train_gather_comp1)
unique(train_gather$bin_frame)
train_gather_dcast<- train_gather%>%
  arrange(filename,nm_comp,bin_frame)%>%
  mutate(bin_frame = paste0("t_", paste0(bin_frame)))%>%
 data.table::dcast(timersies_unique+filename+subject+expression+drug.placebo+subject+nm_comp~bin_frame, value.var = "nmf_comp_value")


colnames(train_gather_dcast)
ts_order

train_gather_dcast<- bind_cols(train_gather_dcast[,1:7], train_gather_dcast[,c(ts_order)])

# now derive param,eters for the timeseries
colnames(train_gather_dcast)

# this extracts features from each timeseries - 41 in this case 
# see Multivariate times series classification through an interpretable representation
# Author links open overlay panelFrancisco J.BaldánaJosé M.Beníteza
# https://www.sciencedirect.com/science/article/pii/S0020025521004825#b0180


# we could do somethign similar where we create the features ourselves
# e.g. displacement, speed, RMSSD, jerk, etc, this gives a smaller set of data compared to 
max_min_norm()

range(maxnorm(train_gather_dcast$t_1),na.rm = T)
?max_min_norm
range(max_min_norm(train_gather_dcast$t_1),na.rm = T)

bind_cols(maxnorm(train_gather_dcast$t_1),max_min_norm(train_gather_dcast$t_1))%>%
  ggplot(aes(x =...1, y = ...2))+
  geom_point()
  geom_point(x = maxnorm(train_gather_dcast$t_1),y =  max_min_norm(train_gather_dcast$t_1))


  colnames(train_gather_dcast)
# max norm
  
train_gather_dcast_maxnorm<- train_gather%>%
  group_by(subject)%>%
  mutate(nmf_comp_value = maxnorm(nmf_comp_value))
  
  
train_gather_dcast_maxnorm_dcast<-  train_gather_dcast_maxnorm%>%
  ungroup()%>%
  mutate(bin_frame = paste0("t_", paste0(bin_frame)))%>%
 data.table::dcast(timersies_unique+filename+subject+expression+drug.placebo+subject+nm_comp~bin_frame, value.var = "nmf_comp_value")

  colnames(train_gather_dcast)
  
  # reorder timeseries columns
  
  train_gather_dcast_maxnorm_dcast<- bind_cols(train_gather_dcast_maxnorm_dcast[,1:7], train_gather_dcast_maxnorm_dcast[,c(ts_order)])

colnames(train_gather_dcast[,8:107])

test_ts <- CMFMTS::cmfmts(dataset = train_gather_dcast[,8:107],
                na = TRUE)

View(test_ts)
colnames(train_gather_dcast_maxnorm_dcast)

library(CMFMTS)

# now derive time-series features for the normed timeseries
mts_maxnorm<-  CMFMTS::cmfmts(dataset = train_gather_dcast_maxnorm_dcast[,8:107],
                na = TRUE)

View(test_ts)

View(mts_maxnorm)

cor(test_ts,mts_maxnorm, use="complete.obs")

cor(test_ts$lempel_ziv,mts_maxnorm$lempel_ziv, use="complete.obs")

cor(test_ts$aproximation_entropy, test_ts$sample_entropy, use="complete.obs")
cor(mts_maxnorm$aproximation_entropy, mts_maxnorm$sample_entropy, use="complete.obs")



```

View(train_gather_dcast_maxnorm_dcast)
```{r}
# note some variables are constant and may need to be excluded for classification
# e.g lenght, seasonality
# periods

test_ts$filename<- train_gather_dcast$filename
test_ts$subject<- train_gather_dcast$subject
test_ts$expression<- train_gather_dcast$expression
test_ts$drug.placebo<- train_gather_dcast$drug.placebo
test_ts$nm_comp<- train_gather_dcast$nm_comp
test_ts$nm_comp<- train_gather_dcast$nm_comp

# 
mts_maxnorm$filename<- train_gather_dcast_maxnorm_dcast$filename
mts_maxnorm$subject<- train_gather_dcast_maxnorm_dcast$subject
mts_maxnorm$expression<- train_gather_dcast_maxnorm_dcast$expression
mts_maxnorm$drug.placebo<- train_gather_dcast_maxnorm_dcast$drug.placebo
mts_maxnorm$nm_comp<- train_gather_dcast_maxnorm_dcast$nm_comp
mts_maxnorm$nm_comp<- train_gather_dcast_maxnorm_dcast$nm_comp


mts_maxnorm

# dcast components such that each row only has one timeseries
test_ts
nm_comp
colnames(test_ts)

library(data.table)



test_ts_dcast<-
 setDT(test_ts)%>%
   gather(ts_features, values, -filename,- subject, -expression,-drug.placebo, -nm_comp)%>%
  mutate(ts_features_k =  paste0(ts_features, nm_comp))%>%
  # mutate(bin_frame = paste0("t_", paste0(bin_frame)))%>%
 data.table::dcast(filename + subject+expression+drug.placebo ~ ts_features_k, value.var = "values", sep = "")


mts_maxnorm_dcast<-
 setDT(test_ts)%>%
   gather(ts_features, values, -filename,- subject, -expression,-drug.placebo, -nm_comp)%>%
  mutate(ts_features_k =  paste0(ts_features, nm_comp))%>%
  # mutate(bin_frame = paste0("t_", paste0(bin_frame)))%>%
 data.table::dcast(filename + subject+expression+drug.placebo ~ ts_features_k, value.var = "values", sep = "")


View(test_ts_dcast)

# now test this is a regular model

write_csv(test_ts_dcast,"test_ts_dcast.csv")
write_csv(mts_maxnorm_dcast,"mts_maxnorm_dcast.csv")
# resukts are veru simialr with both
scmfts


```

since this approach  above works, we could derive temporal parameters that need not be super exhaustive
but that will capture the main info in the timeseries
e.g. peak speed, peak discplacement, RMSSD for eitehr speed or displcamenet

```{r}
posed_spoken_bindrows
colnames(posed_spoken_bindrows_ts)

range(posed_spoken_bindrows_ts$k3_comp1_abs_diff, na.rm = T)
options(scipen = 999)
range(posed_spoken_bindrows_ts$k3_comp1, na.rm = T)
posed_spoken_bindrows_ts<- posed_spoken_bindrows_ts%>%
  group_by(filename)%>%

   mutate(k3_comp1_abs_diff = as.numeric(diff(zoo::zoo(k3_comp1), na.pad = TRUE)),
         k3_comp2_abs_diff= as.numeric(diff(zoo::zoo(k3_comp2), na.pad = TRUE)),
         k3_comp3_abs_diff=as.numeric(diff(zoo::zoo(k3_comp3), na.pad = TRUE)))%>%
  
     mutate(k3_comp1_abs_diff_sum = sum(abs(k3_comp1_abs_diff), na.rm = T),
         k3_comp2_abs_diff_sum= sum(abs(k3_comp2_abs_diff),na.rm = T),
         k3_comp3_abs_diff_sum=sum(abs(k3_comp3_abs_diff),na.rm = T))%>%
           
          # speed calculations
  mutate(k3_comp1_speed = (abs(lag(k3_comp1) -k3_comp1))/(abs(lead(bin_frame)-bin_frame)),
         k3_comp2_speed = (abs(lag(k3_comp2) -k3_comp2))/(abs(lead(bin_frame)-bin_frame)),
         k3_comp3_speed = (abs(lag(k3_comp3) -k3_comp3))/(abs(lead(bin_frame)-bin_frame)))%>%
         
        mutate(k3_comp1_speed_sum = sum(k3_comp1_speed, na.rm = T),
         k3_comp2_speed_sum = sum(k3_comp2_speed, na.rm = T),
         k3_comp3_speed_sum = sum(k3_comp3_speed, na.rm = T))%>%
    mutate(
        RMSSD_speed_k1 = sqrt(mean(((lead(k3_comp1_speed ) - k3_comp1_speed )^2),na.rm = TRUE)),
        RMSSD_speed_k2 = sqrt(mean(((lead(k3_comp2_speed ) - k3_comp2_speed )^2),na.rm = TRUE)),
        RMSSD_speed_k3 = sqrt(mean(((lead(k3_comp3_speed ) - k3_comp3_speed )^2),na.rm = TRUE)))%>%
   mutate(
        RMSSD_disp_k1 = sqrt(mean(((lead(k3_comp1_abs_diff ) - k3_comp1_abs_diff )^2),na.rm = TRUE)),
        RMSSD_disp_k2 = sqrt(mean(((lead(k3_comp2_abs_diff ) - k3_comp2_abs_diff )^2),na.rm = TRUE)),
        RMSSD_disp_k3 = sqrt(mean(((lead(k3_comp3_abs_diff ) - k3_comp3_abs_diff )^2),na.rm = TRUE)))


unique(posed_spoken_bindrows_ts$filename)

posed_spoken_bindrows_ts$k3_comp1_abs_diff_sum
posed_spoken_bindrows_ts$k3_comp1_abs_diff

posed_spoken_bindrows_ts$k3_comp1_speed
posed_spoken_bindrows_ts$k3_comp1_speed_sum
posed_spoken_bindrows_ts$RMSSD_speed_k1
posed_spoken_bindrows_ts$RMSSD_disp_k1

posed_spoken_bindrows_ts%>%
  subset(filename == "./cut_posed_angry_day1_p1.csv")%>%
  ggplot(aes(bin_frame, k3_comp1_abs_diff))+
  geom_line()+
  geom_line(aes(y = k3_comp1_abs_diff_sum), color = "red")+
  geom_line(aes(y = k3_comp1_speed), color = "blue")+
  geom_line(aes(y = k3_comp1_speed_sum), color = "green")+
  geom_line(aes(y = RMSSD_speed_k1), linetype = "dashed")+
    geom_line(aes(y = RMSSD_disp_k1), linetype = "dotted")


posed_spoken_bindrows_ts%>%
  # subset(filename == "./cut_posed_angry_day1_p1.csv")%>%
  ggplot(aes(RMSSD_speed_k3, RMSSD_disp_k3))+
  geom_point()
  geom_line()+
  geom_line(aes(y = k3_comp1_abs_diff_sum), color = "red")+
  geom_line(aes(y = k3_comp1_speed), color = "blue")+
  geom_line(aes(y = k3_comp1_speed_sum), color = "green")+
  geom_line(aes(y = RMSSD_speed_k1), linetype = "dashed")+
    geom_line(aes(y = RMSSD_disp_k1), linetype = "dotted")
  
  colnames(posed_spoken_bindrows_ts)
 posed_spoken_bindrows_ts_agg<- posed_spoken_bindrows_ts%>%
    group_by(filename, posed_spoken, expression, drug.placebo, subject)%>%
    summarise_if(is.numeric, mean, na.rm = T)
  
 # aggregated wirth kiematic features
 
```

pcatest
colnames(test_ts_dcast)
test_ts_dcast


```{r}
# delete columns with constant variance

# Identify the numerical columns
num_cols <- sapply(test_ts_dcast, is.numeric)

num_col_names <- names(test_ts_dcast[,num_cols])


# Calculate the standard deviation of each column


# Calculate the sd for the selected columns
sd_values <- apply(test_ts_dcast[, num_col_names], 2, sd, na.rm = T)


# Identify the columns with a standard deviation of zero
zero_sd_cols <- names(which(sd_values == 0))

# Drop the columns with a standard deviation of zero
test_ts_dcast_no0Sd <- test_ts_dcast%>%select(-zero_sd_cols)
View(test_ts_dcast_no0Sd)

mts_maxnorm_dcast_no0Sd <- mts_maxnorm_dcast%>%select(-zero_sd_cols)


# run the PCA

# Identify the infinite and missing values
inf_values <- is.infinite(as.data.frame(test_ts_dcast_no0Sd))
na_values <- is.na(test_ts_dcast_no0Sd)
table(na_values)

# Replace the infinite and missing values with the median of the dataset

# Replace NA values with the column average
test_ts_dcast_no0Sd<- test_ts_dcast_no0Sd %>%
  mutate_if(is.numeric,funs(ifelse(is.na(.), mean(., na.rm = TRUE), .)))

mts_maxnorm_dcast_no0Sd<- mts_maxnorm_dcast_no0Sd %>%
  mutate_if(is.numeric,funs(ifelse(is.na(.), mean(., na.rm = TRUE), .)))


# na_values <- is.na(test_ts_dcast_no0Sd)
# table(na_values)


 colnames(test_ts_dcast_no0Sd)
pca_ts<- prcomp(as.data.frame(test_ts_dcast_no0Sd[,c(5:118)]))
?prcomp
pca_mts_maxnorm<- prcomp(as.data.frame(mts_maxnorm_dcast_no0Sd[,c(5:118)], rank. = 10))

# drop columsn with loading below .5 in the first 9 or 10 dimensions

# rotatest<-promax(pca_ts$rotation)
range(as.data.frame(pca_mts_maxnorm$rotation)$PC1)

as.data.frame(pca_mts_maxnorm$rotation)[,1:3] %>%
  subset((abs(PC1) +abs(PC2)+abs(PC3))  >.5)

range(pca_mts_maxnorm$rotation[,1])
rotatest$loadings[,1:3]

rpt_rotma<- rotatest$rotmat[,1:3]
install.packages("psych")
library(psych)

?principal

?psych::principal
PCA_maxnormpsych <-psych::principal(mts_maxnorm_dcast_no0Sd[,c(5:118)],3, scores = TRUE)
PCA_maxnormpsych

mts_maxnorm_dcast_no0Sd

library(readxl)
toremovePCAmaxnorm <- read_excel("toremovePCAmaxnorm.xlsx")
View(toremovePCAmaxnorm)

mts_maxnorm_dcast_no0Sd_removed<- mts_maxnorm_dcast_no0Sd%>%
select(-c(toremovePCAmaxnorm$remove))


mts_maxnorm_dcast_no0Sd_removed
colnames(mts_maxnorm_dcast_no0Sd_removed)

PCA_maxnormpsych$loadings
mts_maxnorm_dcast_no0Sd_removed

write_csv(mts_maxnorm_dcast_no0Sd_removed, "mts_maxnorm_dcast_no0Sd_removed.csv")

mts_maxnorm_dcast_no0Sd_removed$time_kl_shiftk3_comp1<- NULL
mts_maxnorm_dcast_no0Sd_removed$time_kl_shiftk3_comp2<- NULL
mts_maxnorm_dcast_no0Sd_removed$time_kl_shiftk3_comp3<- NULL

colnames(mts_maxnorm_dcast_no0Sd_removed)
# mts_maxnorm_dcast_no0Sd_removed_SCALE<-scale(mts_maxnorm_dcast_no0Sd_removed[,c(1:64)])

colnames(mts_maxnorm_dcast_no0Sd_removed_SCALE)
PCA_maxnormpsych <-psych::principal(mts_maxnorm_dcast_no0Sd_removed_SCALE[,c(1:64)],3, scores = TRUE)

PCA_maxnormpsych

mts_maxnorm_dcast_no0Sd_removed_SCALE2<- bind_cols(mts_maxnorm_dcast_no0Sd_removed[,1:4],mts_maxnorm_dcast_no0Sd_removed_SCALE)
  
  

  
  PCA_maxnormpsych$scores
  
  
  
  

```

store pc scores
```{r}

mts_maxnorm_dcast_no0Sd_removed_SCALE2$PC1<-   PCA_maxnormpsych$scores[,1]
mts_maxnorm_dcast_no0Sd_removed_SCALE2$PC2<-   PCA_maxnormpsych$scores[,2]
mts_maxnorm_dcast_no0Sd_removed_SCALE2$PC3<-   PCA_maxnormpsych$scores[,3]

colnames(mts_maxnorm_dcast_no0Sd_removed_SCALE2)

mts_maxnorm_dcast_no0Sd_removed_SCALE2_forlmer <- mts_maxnorm_dcast_no0Sd_removed_SCALE2[,c(1:4,69:71)]%>%
  group_by(filename)%>%
  gather(comp, nmf_PCA_comp_value, -c(1:4))


mts_maxnorm_dcast_no0Sd_removed_SCALE2_forlmer%>%
  # gather(component, coef,-bin_frame, -subject, -expression, -drug.placebo,-filename)%>%
  # group_by(filename,component)%>%
  # mutate(coef_max = max(coef),
  #        coef = coef/coef_max)%>%
  # group_by(component, filename, expression)%>%
  # 
  # summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  ggplot(aes(comp, nmf_PCA_comp_value, group = expression, color = expression))+
    geom_jitter(position = position_dodge2(1), alpha = .1)+
  stat_summary(geom = "pointrange", position = position_dodge(1))

  # ggpubr::stat_compare_means()
  # geom_jitter( position = position_dodge2( width = .1))


?geom_jitter
```

# original NMD

colnames(mts_maxnorm_dcast_no0Sd_removed_SCALE2)


mts_maxnorm_dcast_no0Sd_removed_SCALE2_forlmer <- mts_maxnorm_dcast_no0Sd_removed_SCALE2[,c(1:4,69:71)]%>%
  group_by(filename)%>%
  gather(comp, nmf_PCA_comp_value, -c(1:4))



  
write_csv(mts_maxnorm_dcast_no0Sd_removed_SCALE2, "mts_maxnorm_dcast_no0Sd_removed_SCALE2.csv")
  write_csv(mts_maxnorm_dcast_no0Sd_removed_SCALE2_forlmer, "mts_maxnorm_dcast_no0Sd_removed_SCALE2_forlmer.csv")
  

# test_ts_dcast_no0Sd$PC1<- 
# as.matrix(princtewst$scores)[,1]
# test_ts_dcast_no0Sd$PC2<- 
# as.matrix(princtewst$scores)[,2]
# 
# test_ts_dcast_no0Sd$PC3<- 
# as.matrix(princtewst$scores)[,3]


# Load the Rtsne and ggplot2 packages
library(Rtsne)
library(ggplot2)

# Load the dataset

# Calculate the low-dimensional representation of the data using t-SNE
colnames(mts_maxnorm_dcast_no0Sd_removed_SCALE2)

set.seed(44)

table(mts_maxnorm_dcast_no0Sd_removed_SCALE2$expression)

tsne_results <- Rtsne(mts_maxnorm_dcast_no0Sd_removed_SCALE2[,69:71], PCA = FALSE,
                      perplexity=30,theta=0.0)

# Create a t-SNE plot using ggplot2

ggplot(as.data.frame(tsne_results$Y), aes(V1, V2)) +
  geom_point(aes(color = test_ts_dcast_no0Sd$expression), size = 1.5)+
  theme(legend.position = "none")

```



```{r}
# tsne with all the variables
?Rtsne
colnames(mts_maxnorm_dcast_no0Sd_removed_SCALE2)
tsne_results2 <- Rtsne(mts_maxnorm_dcast_no0Sd_removed_SCALE2[,5:68], PCA = FALSE)

ggplot(as.data.frame(tsne_results2$Y), aes(V1, V2)) +
  geom_point(aes(color = test_ts_dcast_no0Sd$expression), size = 1.5)+
  theme(legend.position = "none")

```


```{r}
# Load the Rtsne and plotly packages
# library(Rtsne)
install.packages("plotly")

library(plotly)

# plotly::plot_ly()

# Create a t-SNE plot using plotly

?plot_ly

# tsne_results$Y
plot_ly(as.data.frame(tsne_results$Y), x = ~V1, y = ~V2, type = "scatter", mode = "markers",
        name = test_ts_dcast_no0Sd$expression, colors = c('#636EFA','#EF553B','#00CC96'))
  # scale_color_brewer(palette = "Dark2")
  
```
  
  
Train Randim forest for plotting SDs  


library(caTools)
```{r}
# Train Test Split on both Iris and Mtcars
# train_test_split <- function(df) {
#   set.seed(42)
#   sample = sample.split(df, SplitRatio = 0.8#install.packages("caTools")
#   train = subset(df, sample == TRUE)
#   test  = subset(df, sample == FALSE)
#   return (list(train, test))
# }

library(caTools)
# Unwrapping mtcars


rf_result<- data.frame()
acc_test<- data.frame()

# sample(test_ts_dcast_no0Sd$expression)
install.packages("caret")
library(caret)
install.packages("creditmodel")
library(creditmodel)


# ranfomforest



train_set <- train_test_split(permuted_labels)[[1]]
  test_set <- train_test_split(permuted_labels)[[2]]
  
  # fit therandom forest here
  # set.seed(1234)
  
  # Unshuffled model
  # train model
  set.seed(1)

  
    set.seed(1)
  trainIndex <- createDataPartition(mts_maxnorm_dcast_no0Sd_removed_SCALE2$expression, p = .8, 
                                  list = FALSE, 
                                  times = 1)
  trainIndex
  train_set <- mts_maxnorm_dcast_no0Sd_removed_SCALE2[ trainIndex,]
  test_set  <- mts_maxnorm_dcast_no0Sd_removed_SCALE2[-trainIndex,]
  
  # check
  table(train_set$expression)
  table(test_set$expression)
?train
  
  
  # fit the model
  # ?trainControl
  # 
  # fitControl <- trainControl(## 10-fold CV
  #                          method = "repeatedcv",
  #                          number = 10,
  #                          ## repeated ten times
  #                          repeats = 100,
  #                          p = .80)
  
  # rfc = RandomForestClassifier(random_state=1)
  
  r.forest_mts <- train(expression ~ PC1 + PC2 + PC3, 
                data = train_set, 
                method = "rf",
                ntree = 30)
  
  r.forest_tr
  
r.forest_tr$finalModel 

  test_set$prediction <- predict(r.forest_mts, test_set)
  
  
  #create confusion matrix and calculate metrics related to confusion matrix
confusionMatrix(pred, actual, mode = "everything", positive="1")

library(caret)
test<- confusionMatrix(test_set$prediction , as.factor(test_set$expression), mode = "everything", positive="1")

 test_set$prediction
  

r.forest_mts$results

r.forest_mts$trainingData
r.forest_mts$bestTune
r.forest_mts$resample

r.forest_mts$finalModel
r.forest_mts$results
r.forest_mts$finalModel$err.rate

r.forest_mts$finalModel$confusion
r.forest_mts$finalModel$
r.forest_mts$finalModel$forest
# obb
# 100-23.5 = 76.5 #matches jasp


# 
# r.forest_tr$metric
# r.forest_tr$finalModel
# 
# r.forest_tr$finalModel$err.rate
# 
# r.forest_tr$trainingData
  
Acc_unshuff<- sum(test_set$prediction == test_set$expression)/length(test_set$expression)
# Acc_unshuff = 0.8888889 = approximate to what we have
# now we get exactly the same

# we can get acuracy p value and uper lower bounds ysing a binomial test
# https://rdrr.io/cran/caret/man/confusionMatrix.html

# get evaluation metris with SD
confusionMatrix(test_set$prediction , as.factor(test_set$expression), mode = "everything", positive="1")

# some idea about boostraping on repeated measures
# https://colauttilab.github.io/EcologyTutorials/bootstrap.html
# http://math.furman.edu/~dcs/courses/math47/R/library/Hmisc/html/rm.boot.html
# i think this is what I did for my other paper on autonomic coherence





```


<!-- Get a p value -->
# now results are much closer
# can i have more trees than rows random forest?


```{r}
boundary(r.forest_tr, x, class = "Species", main = "Random Forest")

test_set_tem
i = 1

rf_results_df<- data.frame()
rf_finalmodel<- data.frame()
rf_confusion<- data.frame()
acc_test<-data.frame()

by_class_df_perm<-data.frame()
conf_mat_df_perm<-data.frame()

library(caret)
library(randomForest)



for (i in 1:2000) {
    set.seed(i)
message("Star Loop - ", i)
  permuted_labels<- mts_maxnorm_dcast_no0Sd_removed_SCALE2%>%
    mutate(expression_shuffle = sample(expression))
  
  
    trainIndex_temp <- createDataPartition(permuted_labels$expression, p = .8, 
                                  list = FALSE, 
                                  times = 1)
  # trainIndex
  train_set_temp <- permuted_labels[ trainIndex_temp,]
  test_set_temp  <- permuted_labels[-trainIndex_temp,]

  
  # # lets see if we don't shuffle tst
  #   train_set <- train_test_split(test_ts_dcast_no0Sd)[[1]]%>%
  #   
  #    # train_set<- train_set%>%
  #   mutate(expression_shuffle = sample(expression))
  #    
  # test_set <- train_test_split(test_ts_dcast_no0Sd)[[2]]%>%
  #   mutate(expression_shuffle = sample(expression))
  
  
  # fit therandom forest here
  # set.seed(1234)
  # train model
  
  
message("Fit RF - ", i)
  r.forest_temp <- train(expression_shuffle ~ PC1 + PC2 + PC3, 
                data = train_set_temp, 
                method = "rf",
                ntree = 30)
  
  rf_results_df<- bind_rows(rf_results_df,  r.forest_temp$results)
  rf_finalmodel<- bind_rows(rf_finalmodel,  as.data.frame(r.forest_temp$finalModel$err.rate))
  rf_confusion<- bind_rows(rf_confusion,  as.data.frame(r.forest_temp$finalModel$confusion))

  # test set
  test_set_temp$prediction <- predict(r.forest_temp, test_set_temp)
  
  
  # acc_temp <- sum(test_set_temp$prediction == test_set_temp$expression_shuffle)/length(test_set_temp$expression_shuffle)


  acc_temp <- confusionMatrix(test_set_temp$prediction , as.factor(test_set_temp$expression), mode = "everything", positive="1")[["overall"]][["Accuracy"]]
  
  acc_test<- bind_rows(acc_test,as.data.frame(acc_temp))
  
  # sum(test_set_temp$prediction == test_set_temp$expression)/length(test_set_temp$expression)

# confusionMatrix(pred, actual, mode = "everything", positive="1")

# library(caret)
conf_mat_temp_perm <- as.data.frame(confusionMatrix(test_set_temp$prediction , as.factor(test_set_temp$expression), mode = "everything", positive="1")[["table"]])

conf_mat_df_perm<- bind_rows(conf_mat_df_perm,conf_mat_temp_perm)

  
  by_class_temp_perm<- t(as.data.frame(confusionMatrix(test_set_temp$prediction, as.factor(test_set_temp$expression), mode = "everything", positive="1")[["byClass"]]))
  
by_class_df_perm <- bind_rows(as.data.frame(by_class_df), as.data.frame(by_class_temp_perm))

message("Done Loop - ", i)

}

# rep(1:1000, each = 2)
rf_results_df$sim<- rep(1:1000, each = 2)

rf_finalmodel$sim<- rep(1:1000, each = 30)
rf_finalmodel$tree<- rep(1:30,times = 1000)
rf_confusion$sim<- rep(1:1000, each = 3)
acc_test$sim<- 1:1000


rf_results_df
Acc_unshuff
acc_test$acc_temp

acc_test <- acc_test%>%
 mutate(acc_test_z = scale(acc_temp))

# acc_test%>%
  # subset(acc_test_z > 1.63)
# 0.4766667
  # mutate(cutoff = if_else(acc_test_z == 1.64, acc_temp, NULL))
  
  # p < .05 one tailed == 1.93
  acc_test%>%
  ggplot(aes(acc_temp)) +
  geom_histogram() +
  geom_vline(xintercept = 0.47, linetype = "dashed", color = "red")+
  
  geom_vline(aes(xintercept = Acc_unshuff), color = "green")
  # geom_histogram(bins = 100)
  
  
  
  conf_mat_df_perm%>%
    ggplot(aes(Prediction, Reference, fill = Freq/15))+
    geom_tile()+
       # scale_fill_viridis_c(option = "magma")
    scale_fill_viridis_c(option = "magma", breaks=c(0,.5,1),
                       limits =c(0,1))
  

as.data.frame(confusionMatrix(test_set$prediction , as.factor(test_set$expression), mode = "everything", positive="1")[["table"]])%>%
      ggplot(aes(Prediction, Reference, fill = Freq/15))+
    geom_tile()+
       # scale_fill_viridis_c(option = "magma")
    scale_fill_viridis_c(option = "magma", breaks=c(0,.5,1),
                       limits =c(0,1))
  
  

  # by_class_temp_perm



```
  
  # for each

```{r}
rf_finalmodel

# r.forest_mts
as.data.frame(r.forest_mts$finalMode$err.rate)%>%
  summarise_if(is.numeric, mean, na.rm = T)

rf_finalmodel%>%
  group_by(sim)%>%

  summarise_if(is.numeric, mean, na.rm = T)%>%
    gather(key, value, -sim, -tree)%>%
  ggplot(aes(value, color = key)) +
  geom_histogram()+
  # facet_grid(~key)+
    geom_vline(xintercept = .3)
# rhe lowest error we have in the real is .3


rf_results_df


rf_results_df %>%
  ggplot(aes(Accuracy)) +
  geom_histogram()+
  # facet_grid(~key)+
    geom_vline(xintercept = .76) #r.forest_mts$results


# by_class_temp_perm
by_class_df_perm

rf_confusion$class<-substring(rownames(rf_confusion), 1,3)

rf_confusion%>%
  group_by(class)%>%summarise_if(is.numeric, mean, na.rm = T)

r.forest_mts$finalModel$confusion





# p value will be the number of time acc in shuffled dataset is greater than observed accuracy
```

boostraping CIs

```{r}
rf_results_df_ci<- data.frame()
rf_finalmodel_ci<- data.frame()
rf_confusion_ci<- data.frame()
acc_test_ci<-data.frame()
by_class_df<- data.frame()
conf_mat_df<- data.frame()

library(caret)
library(randomForest)


# install.packages("fabricatr")

?fabricatr::resample_data



ci_data_resamp_test<- fabricatr::resample_data(mts_maxnorm_dcast_no0Sd_removed_SCALE2, 
                                  N = 43,
                                  ID_labels = "subject",
                                  unique_labels = FALSE#this tedn to reat isues when true
                                  )

ci_data_resamp_test


```


# options(scipen = 999)
# mean(abs(ci_data_resamp_test$aproximation_entropyk3_comp2))
# mean(abs(mts_maxnorm_dcast_no0Sd_removed_SCALE2$aproximation_entropyk3_comp2))

```{r}

unique(as.factor(as.character(ci_data_resamp_test$subject)))

ci_data_resamp_test

# i = 1

unique(ci_data_resamp_test$expression)

for (i in 1:10000) {
    set.seed(i)
message("Star Loop - ", i)

ci_data_resamp_test<- fabricatr::resample_data(mts_maxnorm_dcast_no0Sd_removed_SCALE2, 
                                  N = 43,
                                  ID_labels = "subject",
                                  unique_labels = FALSE)#this tedn to reat isues when true
  
  
    trainIndex_temp <- createDataPartition(ci_data_resamp_test$expression, p = .8, 
                                  list = FALSE, 
                                  times = 1)
  # trainIndex
  train_set_temp <- ci_data_resamp_test[ trainIndex_temp,]
  test_set_temp  <- ci_data_resamp_test[-trainIndex_temp,]

  
  # # lets see if we don't shuffle tst
  #   train_set <- train_test_split(test_ts_dcast_no0Sd)[[1]]%>%
  #   
  #    # train_set<- train_set%>%
  #   mutate(expression_shuffle = sample(expression))
  #    
  # test_set <- train_test_split(test_ts_dcast_no0Sd)[[2]]%>%
  #   mutate(expression_shuffle = sample(expression))
  
  
  # fit therandom forest here
  # set.seed(1234)
  # train model
  
  
message("Fit RF - ", i)
  r.forest_temp <- train(expression ~ PC1 + PC2 + PC3, 
                data = train_set_temp, 
                method = "rf",
                ntree = 30)
  
  rf_results_df_ci<- bind_rows(rf_results_df_ci,  r.forest_temp$results)
  
  rf_finalmodel_ci<- bind_rows(rf_finalmodel_ci,  as.data.frame(r.forest_temp$finalModel$err.rate))
  
  rf_confusion_ci<- bind_rows(rf_confusion_ci,  as.data.frame(r.forest_temp$finalModel$confusion))

  # test set
  test_set_temp$prediction <- predict(r.forest_temp, test_set_temp)
  
acc_temp <- confusionMatrix(test_set_temp$prediction , as.factor(test_set_temp$expression), mode = "everything", positive="1")[["overall"]][["Accuracy"]]

# test_set$prediction
  

  # sum(test_set_temp$prediction == test_set_temp$expression)/length(test_set_temp$expression)

# confusionMatrix(pred, actual, mode = "everything", positive="1")

# library(caret)
conf_mat_temp<- as.data.frame(confusionMatrix(test_set_temp$prediction , as.factor(test_set_temp$expression), mode = "everything", positive="1")[["table"]])

conf_mat_df<- bind_rows(conf_mat_df,conf_mat_temp)

by_class_temp<- t(as.data.frame(confusionMatrix(test_set_temp$prediction, as.factor(test_set_temp$expression), mode = "everything", positive="1")[["byClass"]]))

by_class_df<- bind_rows(as.data.frame(by_class_df), as.data.frame(by_class_temp))



message("Done Loop - ", i)

}


  r.forest_mts <- train(expression ~ PC1 + PC2 + PC3, 
                data = train_set, 
                method = "rf",
                ntree = 30)
  
  r.forest_tr
  
r.forest_tr$finalModel 

  test_set$prediction <- predict(r.forest_mts, test_set)
  

```

```

```{r}
conf_mat_df

by_class_temp


# as.data.frame(r.forest_mts$finalMode$err.rate)%>%
rnames<- row.names(by_class_df)

by_class_df$sim<- rep(1:1000, each = 10)

library(tidyverse)

by_class_df%>%
  mutate(row_name = substr(rnames,1,8)) %>%
  subset(row_name == "Balanced")%>%

    gather(key, value, -sim, -row_name) %>%
    group_by(key)%>%
    mutate(perc_5 = quantile(value,.025, na.rm = TRUE),
         perc_95 = quantile(value,.975, na.rm = TRUE))%>%
  # 0.8833       0.9500     0.9167


  mutate(acc_test = if_else(key == "Class: angry", .88,
                  if_else(key == "Class: happy", .95,
                          if_else(key == "Class: sad",.91, NULL))))%>%
  group_by(key)%>%
  # summarise_if(is.numeric, mean, na.rm = T)%>%
  ggplot(aes(log(value+.1), color = key)) +
  geom_histogram() +
  facet_grid(~key) +
    geom_vline(aes(xintercept = log(perc_5+.1))) +
   geom_vline(aes(xintercept =log(perc_95+.1))) +
    geom_vline(aes(xintercept = log(acc_test+.1)), linetype ="dashed", color = "red")\



# bar plots
# ?contains()

by_class_df_acc<- by_class_df%>%
mutate(row_name = substr(rnames,1,19)) %>%
  filter(str_detect(row_name, "Balanced Accuracy"))

bind_cols(acc_test_ci,
by_class_df_acc)%>%

  # filter(str_detect(row_name, "Balanced Accuracy"))%>%
# mutate(test= contains(,row_name)) %>%
    gather(key, value, -sim...2,-sim...6,-row_name) %>%
    mutate(key = if_else(key!="acc_temp", substr(key,7,19), "Global Acc")) %>%
    group_by(key)%>%
    mutate(perc_5 = quantile(value,.025, na.rm = TRUE),
         perc_95 = quantile(value,.975, na.rm = TRUE))%>%
  mutate(serror = sd(value) / sqrt(n())) %>%

  # 0.8833       0.9500     0.9167

  mutate(acc_test = if_else(key == "angry", .88,
                  if_else(key == "happy", .95,
                          if_else(key == "sad",.91, 0.8889)))) %>%
  group_by(key)%>%
  summarise_if(is.numeric, mean, na.rm = T) %>%
  ggplot(aes(key, log(value+.01), color = key)) +
   geom_bar(stat="identity", width = .11)+
  geom_point(aes(x = key, y = log(acc_test+.01)))+
  geom_errorbar( aes(x=key, ymin=log(perc_5+.01), ymax=log(perc_95+.01)), width=0.4, colour="orange", alpha=0.9, size=1.3)
  # coord_cartesian(ylim=c(.7,1))
  # ylim(.30,1)
  facet_grid(~key) +
    geom_vline(aes(xintercept = log(perc_5+.01))) +
   geom_vline(aes(xintercept =log(perc_95+.1))) +
    geom_vline(aes(xintercept = log(acc_test+.1)), linetype ="dashed", color = "red")

```

CHAT GPT bootsraped CIs for random forest
```{r}
# Load the necessary packages
library(randomForest)

# Create a function to calculate the three-way classification accuracy
calculate_accuracy <- function(data, model) {
  # Make predictions on the data using the model
  predictions <- predict(model, data)
  
  # Calculate the three-way classification accuracy
  accuracy <- sum(predictions == data$class) / nrow(data)
  
  return(accuracy)
}

# Load the data and fit the random forest model
data <- read.csv("data.csv")
model <- randomForest(class ~ ., data = data)

# Set the number of bootstrapped samples
n <- 1000

# Initialize a vector to store the accuracy values
accuracy_values <- rep(NA, n)

# Generate the indices for the bootstrapped samples
indices <- sample(nrow(data), size = n, replace = TRUE)

# Iterate over the indices and calculate the three-way classification accuracy
for (i in 1:n) {
  # Create a bootstrapped sample
  sample_data <- data[indices[i], ]
  
  # Calculate the three-way classification accuracy
  accuracy_values[i] <- calculate_accuracy(sample_data, model)
}

# Calculate the standard error
standard_error <- sd(accuracy_values) / sqrt(n)

# Print the standard error
print(standard_error)


  
  r.forest_mts$finalModel
  geom_vline(xintercept = mean(r.forest_mts$finalModel$err.rate[,4]), linetype = "dashed", color = "red")
# here we have some issue where the poitn estimate is oiutside the CI
# https://stats.stackexchange.com/questions/388931/bootstrap-confidence-intervals-do-not-include-the-observed-mean-can-this-be
# https://stats.stackexchange.com/questions/355781/is-it-true-that-the-percentile-bootstrap-should-never-be-used/357498#357498

# rhe lowest error we have in the real is .3
r.forest_mts$finalModel$err.rate
r.forest_mts$results

r.forest_mts

r.forest_mts$trainingData
(0.04/sqrt(183))+.77

.77-(0.04/sqrt(183))


```

```{r}
library(boot)


  boot.kn <- function(data, indices, formula, newdata, k){
  d <- data[indices, ]
  fit <- knnreg(formula, data = d)
  predict(fit, newdata = newdata)
}

set.seed(2021)
R <- 1e4
bs <- boot(df1, boot.kn, R = R, formula = b ~ a, newdata = newdata, k = k)
ci <- boot.ci(bs, level = 0.95, type = "bca")

#https://stackoverflow.com/questions/69641922/how-can-i-perform-bootstrap-to-find-the-confidence-interval-for-a-k-nn-model-in
boot.kn <- function(data, indices, formula, newdata, k){
  d <- data[indices, ]
  fit <- knnreg(formula, data = d)
  predict(fit, newdata = newdata)
}

set.seed(2021)
R <- 1e4
bs <- boot(df1, boot.kn, R = R, formula = b ~ a, newdata = newdata, k = k)
ci <- boot.ci(bs, level = 0.95, type = "bca")


```



```{r}
rf_results_df_ci$sim<- rep(1:5000, each = 2)

rf_finalmodel_ci$sim<- rep(1:5000, each = 30)
rf_finalmodel_ci$tree<- rep(1:30,times = 5000)
rf_confusion_ci$sim<- rep(1:5000, each = 3)
acc_test_ci$sim<- 1:5000


rf_results_df


Acc_unshuff

acc_test$acc_temp


acc_test<- acc_test%>%
 mutate(acc_test_z = scale(acc_temp))


  # subset(acc_test_z > 1.63)
# 0.4766667
  # mutate(cutoff = if_else(acc_test_z == 1.64, acc_temp, NULL))
  
  # p < .05 one tailed == 1.93
max(acc_test_ci$acc_temp)

percent_rank()
# quantile(96%)

quantile(acc_test_ci$acc_temp, .25)

acc_test_ci%>%
  ggplot(aes(acc_temp)) +
  geom_histogram() +
  # geom_vline(xintercept = 0.47, linetype = "dashed", color = "red")+
  
  geom_vline(aes(xintercept = quantile(acc_test_ci$acc_temp, .15)), color = "green")+
  geom_vline(aes(xintercept = quantile(acc_test_ci$acc_temp, .95)), color = "green")+  

  geom_histogram(bins = 100)
  

  # for each


rf_finalmodel

r.forest_mts
as.data.frame(r.forest_mts$finalMode$err.rate)%>%
  summarise_if(is.numeric, mean, na.rm = T)

rf_finalmodel_ci%>%
  group_by(sim)%>%

  summarise_if(is.numeric, mean, na.rm = T)%>%
    gather(key, value, -sim, -tree)%>%
  ggplot(aes(value, color = key)) +
  geom_histogram()
  # facet_grid(~key)+
    # geom_vline(xintercept = .3)
# rhe lowest error we have in the real is .3

```


rf_results_df

```{r}
rf_results_df_ci %>%
  ggplot(aes(Accuracy)) +
  geom_histogram()+
  # facet_grid(~key)+
    geom_vline(xintercept = .76) #r.forest_mts$results


rf_confusion$class<-substring(rownames(rf_confusion), 1,3)

rf_confusion%>%
  group_by(class)%>%summarise_if(is.numeric, mean, na.rm = T)

r.forest_mts$finalModel$confusion


rf_results_df


Acc_unshuff

acc_test$acc_temp


acc_test<- acc_test%>%
 mutate(acc_test_z = scale(acc_temp))


  # p < .05 one tailed == 1.93
  acc_test_ci%>%
        mutate(perc_5 = quantile(acc_temp,.025, na.rm = TRUE), 
         perc_95 = quantile(acc_temp,.975, na.rm = TRUE))%>%
  ggplot(aes(log(acc_temp+.1))) +
  geom_histogram() 
  # geom_vline(xintercept = 0.47, linetype = "dashed", color = "red")+
   #  geom_vline(aes(xintercept =perc_5))+
   # geom_vline(aes(xintercept =perc_95))+
  
  geom_vline(aes(xintercept = Acc_unshuff), color = "green", linetype = "dashed")
  # geom_histogram(bins = 100)
  
```
  
```{r}
  # note CIs wont always be symtric
  # https://stats.stackexchange.com/questions/16574/are-confidence-intervals-always-symmetrical-around-the-point-estimate#:~:text=A%20confidence%20interval%20obtained%20from,on%20the%20natural%20log%20scale.
  

  # for each emotion
  
  rf_result
  rf_finalmodel
  rf_finalmodel
  
  
  rf_confusion_ci
 acc_test_ci%>%
        mutate(perc_5 = quantile(acc_temp,.025, na.rm = TRUE), 
         perc_95 = quantile(acc_temp,.975, na.rm = TRUE))%>%
  ggplot(aes(acc_temp)) +
  geom_histogram() +
  # geom_vline(xintercept = 0.47, linetype = "dashed", color = "red")+
    geom_vline(aes(xintercept =perc_5))+
   geom_vline(aes(xintercept =perc_95))+
  
  geom_vline(aes(xintercept = Acc_unshuff), color = "green", linetype = "dashed") 
  
  
  
```


```{r}
rf_finalmodel

r.forest_mts
as.data.frame(r.forest_mts$finalMode$err.rate)%>%
  summarise_if(is.numeric, mean, na.rm = T)

rf_finalmodel_ci%>%
  group_by(sim)%>%

  summarise_if(is.numeric, mean, na.rm = T)%>%

    gather(key, value, -sim, -tree)%>%
  # subset(key == "OBB")%>%
    group_by(key)%>%
    mutate(perc_5 = quantile(value,.025, na.rm = TRUE), 
         perc_95 = quantile(value,.975, na.rm = TRUE))%>%
  mutate(err_test = if_else(key == "angry", 0.24590164,
                  if_else(key == "happy", 0.09836066,
                          if_else(key == "sad",0.36065574, 0.2319615))))%>%
  ggplot(aes(value, color = key)) +
  geom_histogram() +
  facet_grid(~key) +
    geom_vline(aes(xintercept =perc_5)) +
   geom_vline(aes(xintercept =perc_95)) +
    geom_vline(aes(xintercept = err_test), lintype ="dashed", color = "red")
  
  r.forest_mts$finalModel
  geom_vline(xintercept = mean(r.forest_mts$finalModel$err.rate[,4]), linetype = "dashed", color = "red")
# here we have some issue where the poitn estimate is oiutside the CI
# https://stats.stackexchange.com/questions/388931/bootstrap-confidence-intervals-do-not-include-the-observed-mean-can-this-be
# https://stats.stackexchange.com/questions/355781/is-it-true-that-the-percentile-bootstrap-should-never-be-used/357498#357498

# rhe lowest error we have in the real is .3
r.forest_mts$finalModel$err.rate
r.forest_mts$results

r.forest_mts

r.forest_mts$trainingData
(0.04/sqrt(183))+.77

.77-(0.04/sqrt(183))

```
                 

```{r}
rf_results_df


rf_results_df %>%
  ggplot(aes(Accuracy)) +
  geom_histogram()+
  # facet_grid(~key)+
    geom_vline(xintercept = .76) #r.forest_mts$results

rf_confusion$class<-substring(rownames(rf_confusion), 1,3)

rf_confusion%>%
  group_by(class)%>%summarise_if(is.numeric, mean, na.rm = T)

r.forest_mts$finalModel$confusion





# p value will be the number of time acc in shuffled dataset is greater than observed accuracy



```



```{r}
sum(acc_test[1:101,] >.33)/100
sum(acc_test$acc_testp>Acc_unshuff)/length(acc_test$acc_testp)

p <.001
acc_test<- bind_rows(acc_test,as.data.frame(acc_testp))


# for confidence interval it's a bit diference, we want to boostrap - sample with replacement




test_ts_dcast_no0Sd%>%
  # subset(subject == 15)

install.packages("devtools")

require(devtools)
install_version("randomForest", version = "4.6.14", repos = "http://cran.us.r-project.org")

library(randomForest)
```

```{r}
options(warn = -1)
fig <-  plot_ly(data = as.data.frame(tsne_results$Y) ,x =  ~V1, y = ~V2, z = ~V2, color = ~test_ts_dcast_no0Sd$expression, colors = c('#636EFA','#EF553B','#00CC96') ) %>% 
  add_markers(size = 8) %>%
  layout( 
    xaxis = list(
      zerolinecolor = "#ffff",
      zerolinewidth = 2,
      gridcolor='#ffff'), 
    yaxis = list(
      zerolinecolor = "#ffff",
      zerolinewidth = 2,
      gridcolor='#ffff'),
    scene =list(bgcolor = "#e5ecf6"))
fig
  
  
```
summary(pca_ts)

?princomp
pca_ts_2<- princomp(as.data.frame(scale(test_ts_dcast_no0Sd[,c(5:118)])))

pca_ts_2$loadings

pca_ts_2$scores[,1:3]

# prcomp(scale(test_ts_dcast_no0Sd[,c(5:118)]))


pca_ts$rotation

pca_ts$x

```


svd_results <- svd(test_ts_dcast_no0Sd, nu = 0, nv = k)



pcatest<- prcomp(scale(posed_spoken_bindrows_ts_agg[,c(14:16,20:28)]))$x[,1:3]


pcatest<- prcomp(scale(posed_spoken_bindrows_ts_agg[,c(14:16,20:28)]))$x[,1:3]


  write_csv(posed_spoken_bindrows_ts_agg, "posed_spoken_bindrows_ts_agg.csv")
  
  # i gues we can also include trend, non linearity

```


install.packages("dtw")

library(dtw) 
demo(dtw)
?dtw 
plot.dtw


?dtw::dtw()
colnames(df_OF_output_AUsW_unblind_spoken1_2)


df_OF_output_AUsW_unblind_spoken1_2[,c(1,6,14,16:18)]
test_dtw<- df_OF_output_AUsW_unblind_spoken1_2[,c(1,6,14,16:18)]
unique(test_dtw$filename)

subset_test_dtw <- test_dtw%>%subset(filename == "./cut_spoken_angry_day1_p1.csv")
subset_test_dtw2 <- test_dtw%>%subset(filename == "./cut_spoken_happy_day2_p29.csv")

alignment_test <-
  dtw(x = subset_test_dtw[,4:6],y = subset_test_dtw2[,4:6],
      keep=TRUE,
      step=asymmetric,
      open.end=TRUE,open.begin=TRUE)

alignment_test

plot(alignment_test$index1,alignment_test$index2,main="Warping function");

alignment_test$query
alignment_test$reference

alignment_test$index1
alignment_test$index2

alignment_test$index1
plot(alignmentOBE,type="two",off=1);
alignment_test$costMatrix
alignment_test$directionMatrix
alignment_test$stepPattern


alignment_test$localCostMatrix
dtw::dtwPlot(subset_test_dtw2[,4:6])
lines(query[alignment_test$index1]~alignment_test$index2,col="blue")


wq<-warp(alignment_test,index.reference=FALSE)
wt<-warp(alignment_test,index.reference=TRUE);

old.par <- par(no.readonly = TRUE);
par(mfrow=c(2,1));

plot(subset_test_dtw2$AU01_r_Inner_brow_raiser,main="Warping query")
  lines(subset_test_dtw[wq],col="blue")

plot(subset_test_dtw,type="l",col="blue",
  main="Warping reference")
  points(subset_test_dtw2[wt])

par(old.par);


##############
##
## Asymmetric step makes it "natural" to warp
## the reference, because every query index has
## exactly one image (q->t is a function)
##

alignment<- dtw(query,reference,step=asymmetric)
wt<-warp(alignment,index.reference=TRUE);

plot(query,type="l",col="blue",
  main="Warping reference, asymmetric step");
  points(reference[wt]);


```

plots

```{r}
df_OF_output_AUsW_unblind_spoken1_binned$drug.placebo


# drug vs placebo by expression
 df_OF_output_AUsW_unblind_spoken1_binned[,c(1,2:3,9:10,34:36)]%>%
  gather(component, coef,-bin_frame, -subject, -expression, -drug.placebo,-filename)%>%
  
      group_by(component,subject)%>%
  mutate(coef_max = max(coef),
         coef = coef/coef_max) %>%
  
  group_by(expression, component, bin_frame,subject,drug.placebo)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  # ggplot(aes(Dataset, coef , color = Dataset, fill = Dataset))+
  ggplot(aes(bin_frame, coef, color = drug.placebo))+
  geom_smooth()+
  # geom_smooth(aes(group = subject), se = F)+
  # stat_summary(aes(group = subject, color = component), geom = "smooth")+
  facet_grid(expression~component  )+
  theme_classic()+
   xlab("time bin")+
  p$graphstyle_int+
   scale_color_viridis_d(option = "magma")
 
 
 # average effect of drug
 
 df_OF_output_AUsW_unblind_spoken1_binned[,c(1,2:3,9:10,34:36)]%>%
  gather(component, coef,-bin_frame, -subject, -expression, -drug.placebo,-filename)%>%
  
      group_by(filename,component,subject,expression)%>%
  mutate(coef_max = max(coef),
         coef = coef/coef_max
         ) %>%
  
  group_by( component, bin_frame,subject,drug.placebo)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  # ggplot(aes(Dataset, coef , color = Dataset, fill = Dataset))+
  ggplot(aes(bin_frame, coef, color = drug.placebo))+
  geom_smooth()+
  # geom_smooth(aes(group = subject), se = F)+
  # stat_summary(aes(group = subject, color = component), geom = "smooth")+
  facet_grid(~component  )+
  theme_classic()+
   xlab("time bin")+
  p$graphstyle_int+
   scale_color_viridis_d(option = "magma")
 
 

```


heatmap - confusion maps


```{r}

 df_OF_output_AUsW_unblind_spoken1_binned[,c(1,2:3,9:10,34:36)]%>%
  gather(component, coef,-bin_frame, -subject, -expression, -drug.placebo,-filename)%>%
        group_by(filename,component,subject,expression)%>%
  mutate(coef_max = max(coef),
         coef = coef/coef_max
         ) %>%
  group_by(expression, component, drug.placebo)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  ggplot(aes(expression, component, fill = coef))+
    geom_tile()+
  facet_grid(~drug.placebo)+
  theme_classic()+
    scale_fill_viridis_c(option="magma")

```


export for classification


```{r}


# agg

colnames(df_OF_output_AUsW_unblind_spoken1_binned)
df_OF_output_AUsW_unblind_spoken1_binned_agg_no_ts <- df_OF_output_AUsW_unblind_spoken1_binned%>%
  ungroup()%>%
  select(c(3,9:10,17:36))%>%
  # gather( component, coef, -timebin,-Emotion, -Dataset, -morph, -filename)%>%
  group_by(subject,drug.placebo, expression)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)



write_csv(df_OF_output_AUsW_unblind_spoken1_binned, 
          "df_OF_output_AUsW_unblind_spoken1_binned.csv")


df_OF_output_AUsW_unblind_spoken1_binned_agg_no_ts$test_ind<- if_else(df_OF_output_AUsW_unblind_spoken1_binned_agg_no_ts$drug.placebo == "drug", 1, 0)


write_csv(df_OF_output_AUsW_unblind_spoken1_binned_agg_no_ts, 
          "df_OF_output_AUsW_unblind_spoken1_binned_agg_no_ts.csv")
nmfk4_agg_no_ts


```


should we do some filtering and smoothing before NMF

```{r}
colnames(df_OF_output_AUsW_unblind_spoken1_binned)

ma_zoo<- function(x, na.rm = TRUE) {
    return(zoo::rollmean(x,k = 5, fill = NA)) }

options(scipen = 999)


ADD_.1<- function(x, na.rm = TRUE) {
    return(x+.01) }


df_OF_output_AUsW_unblind_spoken1_binned_NOZERO<- df_OF_output_AUsW_unblind_spoken1_binned%>%
    ungroup()%>%
  group_by(filename)%>%
  mutate_at(17:33, ADD_.1)
  



df_OF_output_AUsW_unblind_spoken1_binned_ma<- df_OF_output_AUsW_unblind_spoken1_binned_NOZERO %>%
  ungroup()%>%
  group_by(filename)%>%
  mutate_at(17:33, ma_zoo)


df_OF_output_AUsW_unblind_spoken1_binned_ma<-df_OF_output_AUsW_unblind_spoken1_binned_ma%>%
    group_by(filename)%>%
fill(17:33, .direction = "up")%>%
  fill(17:33, .direction = "down")

  

```


moving average before NMF


```{r}

df_OF_output_AUsW_unblind_spoken1_binned_ma

colnames(df_OF_output_AUsW_unblind_spoken1_binned_ma[,17:33])

table(is.na( df_OF_output_AUsW_unblind_spoken1_binned_ma[,17:33]))

res_k3_spoken1_ma <- NMF::nmf(df_OF_output_AUsW_unblind_spoken1_binned_ma[,17:33], r = 3, 
                  nrun = 200, #number of runs to try and update for
                  seed=123456, #specific seed for reproducibility
                 .options = list( 'v')) #ver

# ife


as.data.frame(res_k3_spoken1_ma@fit@H)%>%
  mutate(component = 1:n())%>%
  gather(AU, coef, -component)%>%
  group_by(component)%>%
  mutate(max_comp = max(coef),
         coef = coef/max_comp,
         # AU = substring(AU,8,40),
         AU_code = substring(AU,4,5)
         )%>%
  arrange(AU_code)%>%
  ggplot(aes(component,AU, fill = coef))+
  geom_tile()+
  theme_classic()+
  # scale_fill_viridis_()
  scale_fill_viridis_c(option = "inferno")+
  xlab("K")+
  p$graphstyle_int+
guides(fill=guide_colorbar(ticks.colour = NA))
```
```{r}
df_OF_output_AUsW_unblind_spoken1_binned_ma$NMFtable_k3<- as.data.frame(res_k3_spoken1_ma@fit@W)$V1

# store components
df_OF_output_AUsW_unblind_spoken1_binned_ma$k3_comp1 = as.data.frame(res_k3_spoken1_ma@fit@W)$V1
df_OF_output_AUsW_unblind_spoken1_binned_ma$k3_comp2 = as.data.frame(res_k3_spoken1_ma@fit@W)$V2
df_OF_output_AUsW_unblind_spoken1_binned_ma$k3_comp3 = as.data.frame(res_k3_spoken1_ma@fit@W)$V3

max(df_OF_output_AUsW_unblind_spoken1_binned_ma$k3_comp1)


df_OF_output_AUsW_unblind_spoken1_binned_ma%>%
  group_by(subject)%>%
  
  ggplot(aes(bin_frame, maxnorm(k3_comp1)))+
  geom_smooth()+
  geom_smooth(aes(y = maxnorm(k3_comp2)))+
  geom_smooth(aes(y = maxnorm(k3_comp3)))+
  facet_grid(~expression)


df_OF_output_AUsW_unblind_spoken1_binned_ma%>%
  group_by(subject)%>%
  
  ggplot(aes(bin_frame, k3_comp1))+
  geom_smooth()+
  geom_smooth(aes(y = k3_comp2))+
  geom_smooth(aes(y = k3_comp3))+
  facet_grid(~expression)

```
  
  

# visualisation based on time


# chool_talk$ts_smooth<- 

colnames(df_OF_output_AUsW_unblind_spoken1_binned_ma)
  
  df_OF_output_AUsW_unblind_spoken1_binned_ma[,c(1,2:3,9:10,34:36)]%>%
  gather(component, coef,-bin_frame, -subject, -expression, -drug.placebo,-filename)%>%
  
      group_by(filename,component,subject,expression)%>%
  mutate(coef_max = max(coef),
         coef = coef/coef_max) %>%
  
  group_by(expression, component, bin_frame,subject)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  # ggplot(aes(Dataset, coef , color = Dataset, fill = Dataset))+
  ggplot(aes(bin_frame, coef, color = component))+
  geom_smooth()+
  # geom_smooth(aes(group = subject), se = F)+
  # stat_summary(aes(group = subject, color = component), geom = "smooth")+
  facet_grid(~expression )+
  theme_classic()+
   xlab("time bin")+
  p$graphstyle_int+
   scale_color_viridis_d(option = "magma")
  
  
  # ts by expression
   df_OF_output_AUsW_unblind_spoken1_binned_ma[,c(1,2:3,9:10,34:36)]%>%
  gather(component, coef,-bin_frame, -subject, -expression, -drug.placebo,-filename)%>%
  
      group_by(filename,component,subject,expression)%>%
  mutate(coef_max = max(coef),
         coef = coef/coef_max) %>%
  
  group_by(expression, component, bin_frame,subject)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  # ggplot(aes(Dataset, coef , color = Dataset, fill = Dataset))+
  ggplot(aes(bin_frame, coef, color = expression))+
  geom_smooth()+
  # geom_smooth(aes(group = subject), se = F)+
  # stat_summary(aes(group = subject, color = component), geom = "smooth")+
  facet_grid(~component  )+
  theme_classic()+
   xlab("time bin")+
  p$graphstyle_int+
   scale_color_viridis_d(option = "magma")


```



```{r}


# drug vs placebo by expression
 df_OF_output_AUsW_unblind_spoken1_binned_ma[,c(1,2:3,9:10,34:36)]%>%
  gather(component, coef,-bin_frame, -subject, -expression, -drug.placebo,-filename)%>%
  
      group_by(filename,component,subject,expression)%>%
  mutate(coef_max = max(coef),
         coef = coef/coef_max) %>%
  
  group_by(expression, component, bin_frame,subject,drug.placebo)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  # ggplot(aes(Dataset, coef , color = Dataset, fill = Dataset))+
  ggplot(aes(bin_frame, coef, color = drug.placebo))+
  geom_smooth()+
  # geom_smooth(aes(group = subject), se = F)+
  # stat_summary(aes(group = subject, color = component), geom = "smooth")+
  facet_grid(expression~component  )+
  theme_classic()+
   xlab("time bin")+
  p$graphstyle_int+
   scale_color_viridis_d(option = "magma")
 
 
 # average effect of drug
 
df_OF_output_AUsW_unblind_spoken1_binned_ma[,c(1,2:3,9:10,34:36)]%>%
  gather(component, coef,-bin_frame, -subject, -expression, -drug.placebo,-filename)%>%
  
      group_by(filename,component,subject,expression)%>%
  mutate(coef_max = max(coef),
         coef = coef/coef_max
         ) %>%
  
  group_by( component, bin_frame,subject,drug.placebo)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  # ggplot(aes(Dataset, coef , color = Dataset, fill = Dataset))+
  ggplot(aes(bin_frame, coef, color = drug.placebo))+
  geom_smooth()+
  # geom_smooth(aes(group = subject), se = F)+
  # stat_summary(aes(group = subject, color = component), geom = "smooth")+
  facet_grid(~component  )+
  theme_classic()+
   xlab("time bin")+
  p$graphstyle_int+
   scale_color_viridis_d(option = "magma")
 
```



JASP findings
- emotion classification is good
- but drug is not good not even within emotion


State-space for spoken stim
```{r}


df_OF_output_AUsW_unblind_spoken1_binned_ma

df_OF_output_AUsW_unblind_posed_binned3_nona_clust_agg4.1_main_seq_sum

# manual clustering

# compute speeds and displacement
unique(df_OF_output_AUsW_unblind_spoken1_binned_ma$filename)
# 304

table(df_OF_output_AUsW_unblind_spoken1_binned_ma$filename)
df_OF_output_AUsW_unblind_spoken1_binned_ma1<- 
  
  df_OF_output_AUsW_unblind_spoken1_binned_ma[,1:36]%>%
  ungroup()%>%
  group_by(filename)%>%
  ungroup()%>%
# speed calculations
  mutate(k3_comp1_speed = (abs(lag(k3_comp1) -k3_comp1))/abs((lead(bin_frame)-bin_frame)),
         k3_comp2_speed = (abs(lag(k3_comp2) -k3_comp2))/abs((lead(bin_frame)-bin_frame)),
         k3_comp3_speed = (abs(lag(k3_comp3) -k3_comp3))/abs((lead(bin_frame)-bin_frame)),
         
      # diff computations
         k3_comp1_diff = as.numeric(diff(zoo::zoo(k3_comp1), na.pad = TRUE)),
         k3_comp2_diff =as.numeric(diff(zoo::zoo(k3_comp2), na.pad = TRUE)),
         k3_comp3_diff =as.numeric(diff(zoo::zoo(k3_comp3), na.pad = TRUE)))%>%

  group_by(filename)%>%
  mutate(n_flename = n())%>%
       ungroup()%>%
  mutate(idno = rep(1:304, each = n_flename))
         
        #  # moving averages
        #  k3_comp1_diff_ma = as.numeric(zoo::rollmean(k3_comp1_diff, k = 5, fill = NA)),
        #  k3_comp2_diff_ma = as.numeric(zoo::rollmean(k3_comp2_diff, k = 5, fill = NA)),
        #  k3_comp3_diff_ma = as.numeric(zoo::rollmean(k3_comp3_diff, k = 5, fill = NA)),
        #    
        #   k3_comp1_speed_ma = as.numeric(zoo::rollmean(k3_comp1_speed, k = 5, fill = NA)),
        # k3_comp2_speed_ma = as.numeric(zoo::rollmean(k3_comp2_speed, k = 5, fill = NA)),
        #  k3_comp3_speed_ma = as.numeric(zoo::rollmean(k3_comp3_speed, k = 5, fill = NA)))%>%


df_OF_output_AUsW_unblind_spoken1_binned_ma1$filename

colnames(df_OF_output_AUsW_unblind_spoken1_binned_ma1)

# chool_talk$substate_illustration <-
df_OF_output_AUsW_unblind_spoken1_binned_ma1 %>%
  
  # compare kmean and manual clustering
  group_by(filename)%>%
   # group_by(idno)%>%
    mutate(sp_avg = (k3_comp1_speed+k3_comp2_speed+k3_comp3_speed)/3)%>%
   mutate(comp_delta_avg = (k3_comp1_diff +k3_comp2_diff+k3_comp3_diff)/3)%>%
   group_by(filename)%>%
  mutate(comp_delta_avg1 = scale(comp_delta_avg))%>%
  # mutate(df, IVMean = rowMeans(select(df, starts_with("IV")), na.rm = TRUE))
  mutate(manual_clust_sp_disp = 
           if_else(sp_avg > (mean(sp_avg, na.rm = TRUE)+ 
                               (1.5*(mad(sp_avg, na.rm = TRUE)))), 
                   # & 
                     # comp_delta_avg > (mean(abs(comp_delta_avg), na.rm = TRUE)+(.5*(mad(abs(comp_delta_avg), na.rm = TRUE)))), 
                   "transition state", "sustain state"))%>%
  group_by(filename, manual_clust_sp_disp)%>%
  
   ungroup()%>%
   subset(filename  == "./cut_spoken_angry_day1_p19.csv")%>%
      select(c(1,2,34:46))%>%
  # select(c(2,52:59, 46:47,38:41,64:66))%>%
  gather(component, coef,-bin_frame,-manual_clust_sp_disp,-filename) %>%
  mutate(var_type = if_else(grepl("diff", component ), "3. diff",
                        if_else(grepl("speed", component ), "2. speed",  
                                if_else(grepl("sp_avg", component ), "3. avg speed",  
                                        if_else(grepl("comp_delta_avg", component ), "5. avg diff",  
                            "1. NMF comp"))))) %>%

  
  # scale so we dob;t have massivelly different sizes acordss variables
   group_by(var_type)%>%
  mutate(coef_z = scale(coef))%>%
  group_by(component, bin_frame,var_type, manual_clust_sp_disp)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE) %>%
  ggplot(aes(bin_frame, coef_z, group = component))+

  geom_rect(aes(xmin = bin_frame, xmax = dplyr::lag(bin_frame), ymin = -Inf, ymax = Inf, fill = factor(manual_clust_sp_disp)), 
            alpha = .2)  +
    geom_line(aes(group = component, linetype = var_type), size = 1)+
  # geom_rect(aes(xmin=kmean_order-0.5, xmax=kmean_order+0.5))+ 
  # geom_smooth(se = F)+
  # facet_grid(expression~component)+
    # ggforce::facet_col(facets = vars(var_type), 
    #                  scales = "free_y", 
    #                  space = "free")+

  theme_classic()+
  facet_grid(var_type~.)+

  # scale_fill_viridis_d(option = "inferno")+
  theme_classic()+
  xlab("time bin")+
  ylab("coef")+
  p$graphstyle_int+
  theme(axis.text.y = element_blank(),
        legend.position = "none",
        strip.text = element_text(size = 5))+
    scale_fill_brewer(palette = "Dark2")






```


```{r}

df_OF_output_AUsW_unblind_spoken1_binned_ma1 %>%
  
  # compare kmean and manual clustering
  group_by(filename)%>%
   # group_by(idno)%>%
    mutate(sp_avg = (k3_comp1_speed+k3_comp2_speed+k3_comp3_speed)/3)%>%
   mutate(comp_delta_avg = (k3_comp1_diff +k3_comp2_diff+k3_comp3_diff)/3)%>%
   group_by(filename)%>%
  mutate(comp_delta_avg1 = scale(comp_delta_avg))%>%
  # mutate(df, IVMean = rowMeans(select(df, starts_with("IV")), na.rm = TRUE))
  mutate(manual_clust_sp_disp = 
           if_else(sp_avg > (mean(sp_avg, na.rm = TRUE)+ 
                               (1.5*(mad(sp_avg, na.rm = TRUE)))), 
                   # & 
                     # comp_delta_avg > (mean(abs(comp_delta_avg), na.rm = TRUE)+(.5*(mad(abs(comp_delta_avg), na.rm = TRUE)))), 
                   "transition state", "sustain state"))%>%
  group_by(filename, manual_clust_sp_disp)%>%
  
   ungroup()%>%
   # subset(filename  == "./cut_spoken_angry_day1_p19.csv")%>%
      select(c(1,2,34:46))%>%
  # select(c(2,52:59, 46:47,38:41,64:66))%>%
  gather(component, coef,-bin_frame,-manual_clust_sp_disp,-filename) %>%
  mutate(var_type = if_else(grepl("diff", component ), "3. diff",
                        if_else(grepl("speed", component ), "2. speed",  
                                if_else(grepl("sp_avg", component ), "3. avg speed",  
                                        if_else(grepl("comp_delta_avg", component ), "5. avg diff",  
                            "1. NMF comp"))))) %>%

  
  # scale so we dob;t have massivelly different sizes acordss variables
   group_by(var_type,filename)%>%
  mutate(coef_z = scale(coef))%>%
  group_by(filename,component, bin_frame,var_type, manual_clust_sp_disp)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE) %>%
  ggplot(aes(bin_frame, filename, fill = coef_z))+

  # geom_rect(aes(xmin = bin_frame, xmax = dplyr::lag(bin_frame), ymin = -Inf, ymax = Inf, fill = factor(manual_clust_sp_disp)), 
            # alpha = .2)  +
    # geom_line(aes(group = component, linetype = var_type), size = 1)+
  # geom_rect(aes(xmin=kmean_order-0.5, xmax=kmean_order+0.5))+ 
  # geom_smooth(se = F)+
  # facet_grid(expression~component)+
    # ggforce::facet_col(facets = vars(var_type), 
    #                  scales = "free_y", 
    #                  space = "free")+

  theme_classic()
  # facet_grid(var_type~.)+

  # scale_fill_viridis_d(option = "inferno")+
  theme_classic()+
  xlab("time bin")+
  ylab("coef")+
  p$graphstyle_int+
  theme(axis.text.y = element_blank(),
        legend.position = "none",
        strip.text = element_text(size = 5))+
    scale_fill_brewer(palette = "Dark2")






df_OF_output_AUsW_unblind_spoken1_binned_ma1 %>%
  
  group_by(filename)%>%
   # group_by(idno)%>%
    mutate(sp_avg = (k3_comp1_speed+k3_comp2_speed+k3_comp3_speed)/3)%>%
   mutate(comp_delta_avg = (k3_comp1_diff +k3_comp2_diff+k3_comp3_diff)/3)%>%
   group_by(filename)%>%
  mutate(comp_delta_avg1 = scale(comp_delta_avg))%>%
  # mutate(df, IVMean = rowMeans(select(df, starts_with("IV")), na.rm = TRUE))
  mutate(manual_clust_sp_disp = 
           if_else(sp_avg > (mean(sp_avg, na.rm = TRUE)+ 
                               (1.5*(mad(sp_avg, na.rm = TRUE)))), 
                   # & 
                     # comp_delta_avg > (mean(abs(comp_delta_avg), na.rm = TRUE)+(.5*(mad(abs(comp_delta_avg), na.rm = TRUE)))), 
                   "transition state", "sustain state"))%>%
  
  
   ungroup()%>%
   # subset(idno  == 10)%>%
      # select(c(2, 9,10, 34:36, 49, 57))%>%
      # select(c(1,2, 9, 43:49, 50:53, 34:36))%>%
  # select(c(2,52:59, 46:47,38:41,64:66))%>%
  # gather(component, coef,-bin_frame,-manual_clust_sp_disp,-idno,-drug.placebo,-expression) %>%
      # gather(component, coef,-bin_frame,-cluster_ordered,-filename,-drug.placebo) %>%
  group_by(filename, bin_frame,manual_clust_sp_disp, drug.placebo,expression)%>%
  
  # summarise_if(is.numeric, mean, na.rm = TRUE) %>%
 ggplot(aes(as.numeric(bin_frame), as.factor(filename)))+
            geom_tile(aes(fill = factor(manual_clust_sp_disp)))+

 # geom_rect(aes(xmin = bin_frame, xmax = dplyr::lag(bin_frame), ymin = -Inf, ymax = Inf, fill = factor(manual_clust_sp_disp)), 
 #            alpha = .9)  +
    # geom_line(aes(group = component))+
  # geom_rect(aes(xmin=kmean_order-0.5, xmax=kmean_order+0.5))+ 
  # geom_smooth(se = F)+
  # facet_grid(expression~component)+
  theme_classic()+
  scale_color_brewer(palette = "dark2")+
  # facet_grid(drug.placebo~expression)+
    # scale_fill_viridis_d(option = "inferno")+
  
  p$graphstyle_int+
  theme(axis.text.y = element_blank(),
        legend.position = "none",
        strip.text = element_text(size = 5))+
    scale_fill_brewer(palette = "Dark2")+
  xlab("time bin")+
  ylab("expression")

  

```

susbatate plots

```{r}
chool_talk$speed_disp_fucntionk1_spoken <-


  df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum%>%
  subset(!is.na(statespace))%>%
  ungroup()%>%
  mutate_if(is.numeric, maxnorm)%>%
  # subset(manual_clust_sp_disp == "transition state")%>%
  
  ggplot(aes(avg_disp_clust_k1,peak_sp_avg_clust_k1, color = expression))+
  geom_point(alpha = .5, size = 1.5)+
 
  # geom_smooth(aes(group = subject), se = F)+
  facet_grid(.~statespace)+
  # geom_smooth(method = "lm", formula = y~x,col="blue", se=FALSE)+
  # geom_smooth(method = "nls", formula = y~A*x^ B, se=FALSE,col="red", 
  #             method.args =list(start=c(A=0,B=0)))
  # 
  
     # geom_smooth(aes(group = expression), method = "glm", formula = y~x,
     #                  method.args = list(start=c(A=0,B=0)), size = .2)+
   geom_smooth(aes(group = expression), method = "glm", se = F, formula = y~log(x+.1),
                      method.args = list(
                                         start=c(A=0,B=0)))+
  
 # geom_smooth(aes(group = expression), method = "glm", formula = y~log(x),
 #                      method.args = list(start=c(A=0,B=0)), size = .2)+
  theme_classic()+
  ggpubr::stat_cor(p.accuracy = .001)+
  ylab("peak speed k1 - au")+
   xlab("displacement k1 - au")+
  scale_color_brewer(palette = "Dark2")+
    scale_x_continuous(breaks = c(0,.5,1), limits = c(0,1))+
  # scale_colour_viridis_d()+
  # ggpubr::stat_conf_ellipse()+
  p$graphstyle_int+
    theme(panel.spacing = unit(1, "cm"))



chool_talk$speed_disp_fucntionk2 

df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum$statespace<- df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum$manual_clust_sp_disp

chool_talk$speed_disp_fucntionk2_spoken<- 
df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum%>%
  subset(!is.na(statespace))%>%
  ungroup()%>%
  mutate_if(is.numeric, maxnorm)%>%
  # subset(manual_clust_sp_disp == "transition state")%>%
  
  ggplot(aes(avg_disp_clust_k2,peak_sp_avg_clust_k2, color = expression))+
  geom_point(alpha = .5, size = 1.5)+
 
  # geom_smooth(aes(group = subject), se = F)+
  facet_grid(.~statespace)+
  # geom_smooth(method = "lm", formula = y~x,col="blue", se=FALSE)+
  # geom_smooth(method = "nls", formula = y~A*x^ B, se=FALSE,col="red", 
  #             method.args =list(start=c(A=0,B=0)))
  # 
  
     # geom_smooth(aes(group = expression), method = "glm", formula = y~x,
     #                  method.args = list(start=c(A=0,B=0)), size = .2)+
   geom_smooth(aes(group = expression), method = "glm", se = F,formula = y~log(x+.1),
                      method.args = list(
                                         start=c(A=0,B=0)))+
  
 # geom_smooth(aes(group = expression), method = "glm", formula = y~log(x),
 #                      method.args = list(start=c(A=0,B=0)), size = .2)+
  theme_classic()+
  ggpubr::stat_cor(p.accuracy = .001)+
  ylab("peak speed k2 - au")+
   xlab("displacement k2 - au")+
  scale_color_brewer(palette = "Dark2")+
    scale_x_continuous(breaks = c(0,.5,1), limits = c(0,1))+
  # scale_colour_viridis_d()+
  # ggpubr::stat_conf_ellipse()+
  p$graphstyle_int+
    theme(panel.spacing = unit(1, "cm"))


chool_talk$speed_disp_fucntionk3_spoken <- df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum%>%
    subset(!is.na(statespace))%>%
ungroup()%>%
  mutate_if(is.numeric, maxnorm)%>%
  # subset(manual_clust_sp_disp == "transition state")%>%
  
  ggplot(aes(avg_disp_clust_k3,peak_sp_avg_clust_k3, color = expression))+
  geom_point(alpha = .5, size = 1.5)+
 
  # geom_smooth(aes(group = subject), se = F)+
  facet_grid(.~statespace)+
  # geom_smooth(method = "lm", formula = y~x,col="blue", se=FALSE)+
  # geom_smooth(method = "nls", formula = y~A*x^ B, se=FALSE,col="red", 
  #             method.args =list(start=c(A=0,B=0)))
  # 
  
     # geom_smooth(aes(group = expression), method = "glm", formula = y~x,
     #                  method.args = list(start=c(A=0,B=0)), size = .2)+
   geom_smooth(aes(group = expression), method = "glm",se = F, formula = y~log(x+.1),
                      method.args = list(
                                         start=c(A=0,B=0)))+
  
 # geom_smooth(aes(group = expression), method = "glm", formula = y~log(x),
 #                      method.args = list(start=c(A=0,B=0)), size = .2)+
  theme_classic()+
  ggpubr::stat_cor(p.accuracy = .001)+
  ylab("peak speed k3 - au")+
   xlab("displacement k3 - au")+
  scale_color_brewer(palette = "Dark2")+
  # scale_colour_viridis_d()+
  # ggpubr::stat_conf_ellipse()+
    scale_x_continuous(breaks = c(0,.5,1), limits = c(0,1))+
  p$graphstyle_int+
    theme(panel.spacing = unit(1, "cm"))

chool_talk$speed_disp_fucntionk1_spoken
chool_talk$speed_disp_fucntionk2_spoken
chool_talk$speed_disp_fucntionk3_spoken

library(patchwork)
chool_talk$speed_displace_fucn_patch_spoken<- (chool_talk$speed_disp_fucntionk1_spoken +chool_talk$speed_disp_fucntionk2_spoken+chool_talk$speed_disp_fucntionk3_spoken)+
   plot_layout(guides = "collect") & theme(legend.position = "top")


chool_talk$speed_displace_fucn_patch+  scale_x_continuous(breaks = c(0,.5,1), limits = c(0,1))
ggsave("speed_displace_fucn_patch2_spoken.tiff", chool_talk$speed_displace_fucn_patch_spoken,
       device = "tiff",
       width = 18, height = 5, dpi = 100)


```





```{r}
df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust<-
df_OF_output_AUsW_unblind_spoken1_binned_ma1 %>%
  
  # compare kmean and manual clustering
  group_by(filename)%>%
   # group_by(idno)%>%
    mutate(sp_avg = (k3_comp1_speed+k3_comp2_speed+k3_comp3_speed)/3)%>%
   mutate(comp_delta_avg = (k3_comp1_diff +k3_comp2_diff+k3_comp3_diff)/3)%>%
   group_by(filename)%>%
  mutate(comp_delta_avg1 = scale(comp_delta_avg))%>%
  # mutate(df, IVMean = rowMeans(select(df, starts_with("IV")), na.rm = TRUE))
  mutate(manual_clust_sp_disp = 
           if_else(sp_avg > (mean(sp_avg, na.rm = TRUE)+ 
                               (1.5*(mad(sp_avg, na.rm = TRUE)))), 
                   # & 
                     # comp_delta_avg > (mean(abs(comp_delta_avg), na.rm = TRUE)+(.5*(mad(abs(comp_delta_avg), na.rm = TRUE)))), 
                   "transition state", "sustain state"))

df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust<-
 df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust%>%
  ungroup()%>%
  group_by(filename, expression, subject)%>%
    # mutate(new = cumsum(manual_clust_sp_disp)) %>%
  mutate(clust_frame_no = rleid(manual_clust_sp_disp))


df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum<- df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust  %>%

group_by(filename,manual_clust_sp_disp)%>%
  mutate(clust_frame_no_bin = n(),
         # speed
         sp_avg_clust_k1 = mean(k3_comp1_speed , na.rm = TRUE),
         sp_avg_clust_k2 = mean(k3_comp2_speed , na.rm = TRUE),
         sp_avg_clust_k3 = mean(k3_comp3_speed , na.rm = TRUE),
         
          avg_disp_clust_k1 = sum(abs(k3_comp1_diff ), na.rm = TRUE),
          avg_disp_clust_k2 = sum(abs(k3_comp2_diff ), na.rm = TRUE),
          avg_disp_clust_k3 = sum(abs(k3_comp3_diff ), na.rm = TRUE),
         # sp_avg_clust_k2 = mean(k3_comp2_speed , na.rm = TRUE),
         # sp_avg_clust_k3 = mean(k3_comp3_speed , na.rm = TRUE),
         
         
        peak_sp_avg_clust_k1 = max(k3_comp1_speed , na.rm = TRUE),
          peak_sp_avg_clust_k2 = max(k3_comp2_speed , na.rm = TRUE),
          peak_sp_avg_clust_k3 = max(k3_comp3_speed , na.rm = TRUE),
         
         RMS_sd_clust_k1 = sqrt(mean(((lead(k3_comp1_speed ) - k3_comp1_speed )^2),na.rm = TRUE)),
        RMS_sd_clust_k2 = sqrt(mean(((lead(k3_comp2_speed ) - k3_comp2_speed )^2),na.rm = TRUE)),
        RMS_sd_clust_k3 = sqrt(mean(((lead(k3_comp3_speed ) - k3_comp3_speed )^2),na.rm = TRUE)))%>%
         
          # 
          # 
          # sp_sd_clust = sd(sp_avg, na.rm = TRUE),
          # RMS_sd_clust = sqrt(mean(((lead(sp_avg) - sp_avg)^2),na.rm = TRUE)),
          # RMS_diff_clust = sqrt(mean((comp_delta_avg^2),na.rm = TRUE)))   %>%
         # )%>%
group_by(filename, manual_clust_sp_disp, expression, subject, drug.placebo)%>%
  summarise_if(is.numeric, mean, na.rm  =TRUE)




#  - don't plot
colnames(df_OF_output_AUsW_unblind_posed_binned3_nona_clust_agg4.1_main_seq)

df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum%>%
  # subset(manual_clust_sp_disp == "stable state")%>%
  
  ggplot(aes(avg_disp_clust_k1,peak_sp_avg_clust_k1, color = expression))+
  geom_point(alpha = .5)+
 
  # geom_smooth(aes(group = subject), se = F)+
  facet_grid(.~manual_clust_sp_disp)+
  # geom_smooth(method = "lm", formula = y~x,col="blue", se=FALSE)+
  # geom_smooth(method = "nls", formula = y~A*x^ B, se=FALSE,col="red", 
  #             method.args =list(start=c(A=0,B=0)))
  # 
  
     # geom_smooth(aes(group = expression), method = "glm", formula = y~x,
     #                  method.args = list(start=c(A=0,B=0)), size = .2)+
   # geom_smooth(aes(group = expression), method = "glm", formula = y~x,
   #                    method.args = list(family = gaussian(link = 'log2'),
   #                                       start=c(A=0,B=0)), size = .2)+
  
 geom_smooth(aes(group = expression), method = "glm", formula = y~log(x+.1),
                      method.args = list(start=c(A=0,B=0)), size = .2)+
  theme_classic()+
  ggpubr::stat_cor()+
  scale_color_brewer(palette = "Dark2")+
  # scale_color_viridis_d(option = "inferno")+
  p$graphstyle_int



df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum%>%
  ungroup()%>%
  mutate_if(is.numeric, maxnorm)%>%
  subset(!is.na(manual_clust_sp_disp))%>%
  # subset(manual_clust_sp_disp == "transition state")%>%
  
  ggplot(aes(avg_disp_clust_k1,peak_sp_avg_clust_k1, color = expression))+
  geom_point(alpha = .5, size = 1.5)+
 
  # geom_smooth(aes(group = subject), se = F)+
  facet_grid(.~manual_clust_sp_disp)+
  # geom_smooth(method = "lm", formula = y~x,col="blue", se=FALSE)+
  # geom_smooth(method = "nls", formula = y~A*x^ B, se=FALSE,col="red", 
  #             method.args =list(start=c(A=0,B=0)))
  # 
  
     # geom_smooth(aes(group = expression), method = "glm", formula = y~x,
     #                  method.args = list(start=c(A=0,B=0)), size = .2)+
   geom_smooth(aes(group = expression), method = "glm",se = F, formula = y~log(x+.1),
                      method.args = list(
                                         start=c(A=0,B=0)))+
  
 # geom_smooth(aes(group = expression), method = "glm", formula = y~log(x),
 #                      method.args = list(start=c(A=0,B=0)), size = .2)+
  theme_classic()+
  ggpubr::stat_cor(p.accuracy = .001)+
  ylab("peak speed k1 - au")+
   xlab("displacement k1 - au")+
  scale_color_brewer(palette = "Dark2")+
    scale_x_continuous(breaks = c(0,.5,1), limits = c(0,1))+
  # scale_colour_viridis_d()+
  # ggpubr::stat_conf_ellipse()+
  p$graphstyle_int+
    theme(panel.spacing = unit(1, "cm"))




df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum_max_norm<- df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum%>%
  ungroup()%>%
  mutate_if(is.numeric, maxnorm)%>%
  subset(!is.na(manual_clust_sp_disp))

write_csv(df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum_max_norm,
          "df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum_max_norm_statespace.csv")
df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum_max_norm


write_csv(df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum,
          "df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_statespace.csv")


df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum

df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum_max_norm



df_OF_output_AUsW_unblind_posed_binned3_nona_clust_agg4.1_main_seq$sp_avg

df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum$sp_avg

df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum$peak_sp_avg_clust_k1
df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum$peak_sp_avg_clust_k2
df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum$peak_sp_avg_clust_k3


# posed
df_OF_output_AUsW_unblind_posed_binned3_nona_clust_agg4.1_main_seq$peak_sp_avg_clust_k1
df_OF_output_AUsW_unblind_posed_binned3_nona_clust_agg4.1_main_seq$peak_sp_avg_clust_k2
df_OF_output_AUsW_unblind_posed_binned3_nona_clust_agg4.1_main_seq$peak_sp_avg_clust_k3

df_OF_output_AUsW_unblind_posed_binned3_nona_clust_agg4.1_main_seq$avg_disp_clust_k1
df_OF_output_AUsW_unblind_posed_binned3_nona_clust_agg4.1_main_seq$avg_disp_clust_k2
df_OF_output_AUsW_unblind_posed_binned3_nona_clust_agg4.1_main_seq$avg_disp_clust_k3

posed_substate<-df_OF_output_AUsW_unblind_posed_binned3_nona_clust_agg4.1_main_seq
# flip to match the NMF flip
posed_substate$avg_disp_clust_k2<- df_OF_output_AUsW_unblind_posed_binned3_nona_clust_agg4.1_main_seq$avg_disp_clust_k3
posed_substate$avg_disp_clust_k3<- df_OF_output_AUsW_unblind_posed_binned3_nona_clust_agg4.1_main_seq$avg_disp_clust_k2


posed_substate$peak_sp_avg_clust_k2<- df_OF_output_AUsW_unblind_posed_binned3_nona_clust_agg4.1_main_seq$peak_sp_avg_clust_k3
posed_substate$peak_sp_avg_clust_k3<- df_OF_output_AUsW_unblind_posed_binned3_nona_clust_agg4.1_main_seq$peak_sp_avg_clust_k2


colnames(df_OF_output_AUsW_unblind_posed_binned3_nona_clust_agg4.1_main_seq)
spoken_substate<- df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum

colnames(spoken_substate)
spoken_substate_1<- spoken_substate%>%
  select(cnames_substate_select)

[,c(1,3:5,54:56,60:65,70)]

cnames_substate_select<- colnames(spoken_substate_1)
posed_substate_1<- posed_substate %>%
  select(cnames_substate_select)

posed_substate_1$posed_spoken<- "posed"

spoken_substate_1$posed_spoken<- "spoken"

spoken_substate_1$manual_clust_sp_disp<- NULL


posed_substate_1$statespace
spoken_substate_1$statespace<-sub(" .*", "", spoken_substate_1$statespace)

bind_rows(posed_substate_1, spoken_substate_1)%>%

  # df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum%>%
  subset(!is.na(statespace))%>%
  subset(expression!= "neutral")%>%
  # subset(statespace != "sustain")%>%
  ungroup()%>%
  group_by(posed_spoken)%>%
  mutate_if(is.numeric, maxnorm)%>%
  # subset(manual_clust_sp_disp == "transition state")%>%
  
  ggplot(aes(avg_disp_clust_k1,peak_sp_avg_clust_k1, color = posed_spoken))+
  geom_point(alpha = .5, size = 1.5)+
 
  # geom_smooth(aes(group = subject), se = F)+
  facet_grid(expression~statespace)+
  # geom_smooth(method = "lm", formula = y~x,col="blue", se=FALSE)+
  # geom_smooth(method = "nls", formula = y~A*x^ B, se=FALSE,col="red", 
  #             method.args =list(start=c(A=0,B=0)))
  # 
  
     # geom_smooth(aes(group = expression), method = "glm", formula = y~x,
     #                  method.args = list(start=c(A=0,B=0)), size = .2)+
   geom_smooth(method = "glm", se = T, formula = y~log(x+.1),
                      method.args = list(
                                         start=c(A=0,B=0)))+
  
 # geom_smooth(aes(group = expression), method = "glm", formula = y~log(x),
 #                      method.args = list(start=c(A=0,B=0)), size = .2)+
  theme_classic()+
  ggpubr::stat_cor(p.accuracy = .001)+
  ylab("peak speed k1 - au")+
   xlab("displacement k1 - au")+
  scale_color_brewer(palette = "Dark2")+
    scale_x_continuous(breaks = c(0,.5,1), limits = c(0,1))+
  # scale_colour_viridis_d()+
  # ggpubr::stat_conf_ellipse()+
  p$graphstyle_int+
    theme(panel.spacing = unit(1, "cm"))


# k2

bind_rows(posed_substate_1, spoken_substate_1)%>%

  # df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum%>%
  subset(!is.na(statespace))%>%
  subset(expression!= "neutral")%>%
  # subset(statespace != "sustain")%>%
  ungroup()%>%
  group_by(posed_spoken)%>%
  mutate_if(is.numeric, maxnorm)%>%
  # subset(manual_clust_sp_disp == "transition state")%>%
  
  ggplot(aes(avg_disp_clust_k2,peak_sp_avg_clust_k2, color = posed_spoken))+
  geom_point(alpha = .5, size = 1.5)+
 
  # geom_smooth(aes(group = subject), se = F)+
  facet_grid(expression~statespace)+
  # geom_smooth(method = "lm", formula = y~x,col="blue", se=FALSE)+
  # geom_smooth(method = "nls", formula = y~A*x^ B, se=FALSE,col="red", 
  #             method.args =list(start=c(A=0,B=0)))
  # 
  
     # geom_smooth(aes(group = expression), method = "glm", formula = y~x,
     #                  method.args = list(start=c(A=0,B=0)), size = .2)+
   geom_smooth(method = "glm", se = T, formula = y~log(x+.1),
                      method.args = list(
                                         start=c(A=0,B=0)))+
  
 # geom_smooth(aes(group = expression), method = "glm", formula = y~log(x),
 #                      method.args = list(start=c(A=0,B=0)), size = .2)+
  theme_classic()+
  ggpubr::stat_cor(p.accuracy = .001)+
  ylab("peak speed k3 - au")+
   xlab("displacement k3 - au")+
  scale_color_brewer(palette = "Dark2")+
    scale_x_continuous(breaks = c(0,.5,1), limits = c(0,1))+
  # scale_colour_viridis_d()+
  # ggpubr::stat_conf_ellipse()+
  p$graphstyle_int+
    theme(panel.spacing = unit(1, "cm"))

# k3

bind_rows(posed_substate_1, spoken_substate_1)%>%

  # df_OF_output_AUsW_unblind_spoken1_binned_ma1_nona_clust_agg_main_seq_sum%>%
  subset(!is.na(statespace))%>%
  subset(expression!= "neutral")%>%
  # subset(statespace != "sustain")%>%
  ungroup()%>%
  group_by(posed_spoken)%>%
  mutate_if(is.numeric, maxnorm)%>%
  # subset(manual_clust_sp_disp == "transition state")%>%
  
  ggplot(aes(avg_disp_clust_k2,peak_sp_avg_clust_k2, color = posed_spoken))+
  geom_point(alpha = .5, size = 1.5)+
 
  # geom_smooth(aes(group = subject), se = F)+
  facet_grid(expression~statespace)+
  # geom_smooth(method = "lm", formula = y~x,col="blue", se=FALSE)+
  # geom_smooth(method = "nls", formula = y~A*x^ B, se=FALSE,col="red", 
  #             method.args =list(start=c(A=0,B=0)))
  # 
  
     # geom_smooth(aes(group = expression), method = "glm", formula = y~x,
     #                  method.args = list(start=c(A=0,B=0)), size = .2)+
   geom_smooth(method = "glm", se = T, formula = y~log(x+.1),
                      method.args = list(
                                         start=c(A=0,B=0)))+
  
 # geom_smooth(aes(group = expression), method = "glm", formula = y~log(x),
 #                      method.args = list(start=c(A=0,B=0)), size = .2)+
  theme_classic()+
  ggpubr::stat_cor(p.accuracy = .001)+
  ylab("peak speed k3 - au")+
   xlab("displacement k3 - au")+
  scale_color_brewer(palette = "Dark2")+
    scale_x_continuous(breaks = c(0,.5,1), limits = c(0,1))+
  # scale_colour_viridis_d()+
  # ggpubr::stat_conf_ellipse()+
  p$graphstyle_int+
    theme(panel.spacing = unit(1, "cm"))




```


```{r}

  
bind_rows(posed_substate_1, spoken_substate_1)%>%
  subset(expression!= "neutral")%>%
    subset(!is.na(statespace))%>%
  ggplot(aes(expression, clust_frame_no_bin, color = posed_spoken))+
  geom_jitter(alpha = .1, width = .1)+
  stat_summary(geom = "pointrange")+
  facet_grid(~statespace)+
  theme_classic()


bind_rows(posed_substate_1, spoken_substate_1)%>%
  subset(expression!= "neutral")%>%
    subset(!is.na(statespace))%>%
  ggplot(aes(expression, sp_avg, color = posed_spoken))+
  geom_jitter(alpha = .1, width = .1)+
  stat_summary(geom = "pointrange")+
  facet_grid(~statespace)+
  theme_classic()


bind_rows(posed_substate_1, spoken_substate_1$)%>%
  subset(expression!= "neutral")%>%
    subset(!is.na(statespace))%>%
  ggplot(aes(expression, abs(comp_delta_avg), color = posed_spoken))+
  geom_jitter(alpha = .1, width = .1)+
  stat_summary(geom = "pointrange")+
  facet_grid(~statespace)+
  theme_classic()

```




```{r}

posed_spoken_bindrows

```